{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f15744-6456-4184-91b4-79fcf9f1da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision tqdm matplotlib onnx onnxscript\n",
    "# sudo docker run -it --rm --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v$(pwd):/run/host -p 8888:8888 nvcr.io/nvidia/pytorch:24.12-py3\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "import torch.utils.data as tud\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as tvt\n",
    "import torchvision.transforms.v2 as tv2\n",
    "import torchvision.transforms.functional as tvf\n",
    "import torchvision.datasets as tds\n",
    "import torchvision.utils as tu\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "cpu_num = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf12fe8-8903-46df-a8f7-4c6f73b0aec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import loaders\n",
    "batchsize = 64\n",
    "DIM, train_loader, val_loader = loaders.get_loaders(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6710146-c743-41fc-bff6-d61e3684b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=None)\n",
    "# Replace the head b/c imagenette has only 10 classes.\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "model = model.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f99b5140-3593-4f69-b592-2bb0af0d67b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found permutation search CUDA kernels\n",
      "[ASP][Info] permutation_search_kernels can be imported.\n",
      "[ASP] torchvision is imported, can work with the MaskRCNN/KeypointRCNN from torchvision.\n",
      "[ASP] Auto skipping pruning conv1::weight of size=torch.Size([64, 3, 7, 7]) and type=torch.float32 for sparsity\n",
      "[ASP] Auto skipping pruning fc::weight of size=torch.Size([10, 512]) and type=torch.float32 for sparsity\n",
      "[set_permutation_params_from_asp] Set permutation needed parameters\n",
      "\tSparse parameter names: ['layer1.0.conv1:weight', 'layer1.0.conv2:weight', 'layer1.1.conv1:weight', 'layer1.1.conv2:weight', 'layer2.0.conv1:weight', 'layer2.0.conv2:weight', 'layer2.0.downsample.0:weight', 'layer2.1.conv1:weight', 'layer2.1.conv2:weight', 'layer3.0.conv1:weight', 'layer3.0.conv2:weight', 'layer3.0.downsample.0:weight', 'layer3.1.conv1:weight', 'layer3.1.conv2:weight', 'layer4.0.conv1:weight', 'layer4.0.conv2:weight', 'layer4.0.downsample.0:weight', 'layer4.1.conv1:weight', 'layer4.1.conv2:weight']\n",
      "\tAll parameter names: ['conv1:weight', 'bn1:weight', 'bn1:bias', 'bn1:running_mean', 'bn1:running_var', 'layer1.0.conv1:weight', 'layer1.0.bn1:weight', 'layer1.0.bn1:bias', 'layer1.0.bn1:running_mean', 'layer1.0.bn1:running_var', 'layer1.0.conv2:weight', 'layer1.0.bn2:weight', 'layer1.0.bn2:bias', 'layer1.0.bn2:running_mean', 'layer1.0.bn2:running_var', 'layer1.1.conv1:weight', 'layer1.1.bn1:weight', 'layer1.1.bn1:bias', 'layer1.1.bn1:running_mean', 'layer1.1.bn1:running_var', 'layer1.1.conv2:weight', 'layer1.1.bn2:weight', 'layer1.1.bn2:bias', 'layer1.1.bn2:running_mean', 'layer1.1.bn2:running_var', 'layer2.0.conv1:weight', 'layer2.0.bn1:weight', 'layer2.0.bn1:bias', 'layer2.0.bn1:running_mean', 'layer2.0.bn1:running_var', 'layer2.0.conv2:weight', 'layer2.0.bn2:weight', 'layer2.0.bn2:bias', 'layer2.0.bn2:running_mean', 'layer2.0.bn2:running_var', 'layer2.0.downsample.0:weight', 'layer2.0.downsample.1:weight', 'layer2.0.downsample.1:bias', 'layer2.0.downsample.1:running_mean', 'layer2.0.downsample.1:running_var', 'layer2.1.conv1:weight', 'layer2.1.bn1:weight', 'layer2.1.bn1:bias', 'layer2.1.bn1:running_mean', 'layer2.1.bn1:running_var', 'layer2.1.conv2:weight', 'layer2.1.bn2:weight', 'layer2.1.bn2:bias', 'layer2.1.bn2:running_mean', 'layer2.1.bn2:running_var', 'layer3.0.conv1:weight', 'layer3.0.bn1:weight', 'layer3.0.bn1:bias', 'layer3.0.bn1:running_mean', 'layer3.0.bn1:running_var', 'layer3.0.conv2:weight', 'layer3.0.bn2:weight', 'layer3.0.bn2:bias', 'layer3.0.bn2:running_mean', 'layer3.0.bn2:running_var', 'layer3.0.downsample.0:weight', 'layer3.0.downsample.1:weight', 'layer3.0.downsample.1:bias', 'layer3.0.downsample.1:running_mean', 'layer3.0.downsample.1:running_var', 'layer3.1.conv1:weight', 'layer3.1.bn1:weight', 'layer3.1.bn1:bias', 'layer3.1.bn1:running_mean', 'layer3.1.bn1:running_var', 'layer3.1.conv2:weight', 'layer3.1.bn2:weight', 'layer3.1.bn2:bias', 'layer3.1.bn2:running_mean', 'layer3.1.bn2:running_var', 'layer4.0.conv1:weight', 'layer4.0.bn1:weight', 'layer4.0.bn1:bias', 'layer4.0.bn1:running_mean', 'layer4.0.bn1:running_var', 'layer4.0.conv2:weight', 'layer4.0.bn2:weight', 'layer4.0.bn2:bias', 'layer4.0.bn2:running_mean', 'layer4.0.bn2:running_var', 'layer4.0.downsample.0:weight', 'layer4.0.downsample.1:weight', 'layer4.0.downsample.1:bias', 'layer4.0.downsample.1:running_mean', 'layer4.0.downsample.1:running_var', 'layer4.1.conv1:weight', 'layer4.1.bn1:weight', 'layer4.1.bn1:bias', 'layer4.1.bn1:running_mean', 'layer4.1.bn1:running_var', 'layer4.1.conv2:weight', 'layer4.1.bn2:weight', 'layer4.1.bn2:bias', 'layer4.1.bn2:running_mean', 'layer4.1.bn2:running_var', 'fc:weight', 'fc:bias']\n",
      "[set_identical_seed] Set the identical seed: 1 for all GPUs to make sure the same results generated in permutation search\n",
      "\n",
      "[permute_model] Permuting the model\n",
      "[build_fx_graph] The torch version is: 2.6.0a0+df5bbc09d1.nv24.12, version major is: 2, version minor is: 6, version minimum is: 0a0+df5bbc09d1\n",
      "[build_fx_graph] The Torch.FX is supported.\n",
      "\n",
      "[build_fx_graph] Print the model structure with pure PyTorch function\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "[print_raw_fx_graph] Print the intermediate representation (IR) with Torch.FX\n",
      "graph():\n",
      "    %x : torch.Tensor [num_users=1] = placeholder[target=x]\n",
      "    %conv1 : [num_users=1] = call_module[target=conv1](args = (%x,), kwargs = {})\n",
      "    %bn1 : [num_users=1] = call_module[target=bn1](args = (%conv1,), kwargs = {})\n",
      "    %relu : [num_users=1] = call_module[target=relu](args = (%bn1,), kwargs = {})\n",
      "    %maxpool : [num_users=2] = call_module[target=maxpool](args = (%relu,), kwargs = {})\n",
      "    %layer1_0_conv1 : [num_users=1] = call_module[target=layer1.0.conv1](args = (%maxpool,), kwargs = {})\n",
      "    %layer1_0_bn1 : [num_users=1] = call_module[target=layer1.0.bn1](args = (%layer1_0_conv1,), kwargs = {})\n",
      "    %layer1_0_relu : [num_users=1] = call_module[target=layer1.0.relu](args = (%layer1_0_bn1,), kwargs = {})\n",
      "    %layer1_0_conv2 : [num_users=1] = call_module[target=layer1.0.conv2](args = (%layer1_0_relu,), kwargs = {})\n",
      "    %layer1_0_bn2 : [num_users=1] = call_module[target=layer1.0.bn2](args = (%layer1_0_conv2,), kwargs = {})\n",
      "    %add : [num_users=1] = call_function[target=operator.add](args = (%layer1_0_bn2, %maxpool), kwargs = {})\n",
      "    %layer1_0_relu_1 : [num_users=2] = call_module[target=layer1.0.relu](args = (%add,), kwargs = {})\n",
      "    %layer1_1_conv1 : [num_users=1] = call_module[target=layer1.1.conv1](args = (%layer1_0_relu_1,), kwargs = {})\n",
      "    %layer1_1_bn1 : [num_users=1] = call_module[target=layer1.1.bn1](args = (%layer1_1_conv1,), kwargs = {})\n",
      "    %layer1_1_relu : [num_users=1] = call_module[target=layer1.1.relu](args = (%layer1_1_bn1,), kwargs = {})\n",
      "    %layer1_1_conv2 : [num_users=1] = call_module[target=layer1.1.conv2](args = (%layer1_1_relu,), kwargs = {})\n",
      "    %layer1_1_bn2 : [num_users=1] = call_module[target=layer1.1.bn2](args = (%layer1_1_conv2,), kwargs = {})\n",
      "    %add_1 : [num_users=1] = call_function[target=operator.add](args = (%layer1_1_bn2, %layer1_0_relu_1), kwargs = {})\n",
      "    %layer1_1_relu_1 : [num_users=2] = call_module[target=layer1.1.relu](args = (%add_1,), kwargs = {})\n",
      "    %layer2_0_conv1 : [num_users=1] = call_module[target=layer2.0.conv1](args = (%layer1_1_relu_1,), kwargs = {})\n",
      "    %layer2_0_bn1 : [num_users=1] = call_module[target=layer2.0.bn1](args = (%layer2_0_conv1,), kwargs = {})\n",
      "    %layer2_0_relu : [num_users=1] = call_module[target=layer2.0.relu](args = (%layer2_0_bn1,), kwargs = {})\n",
      "    %layer2_0_conv2 : [num_users=1] = call_module[target=layer2.0.conv2](args = (%layer2_0_relu,), kwargs = {})\n",
      "    %layer2_0_bn2 : [num_users=1] = call_module[target=layer2.0.bn2](args = (%layer2_0_conv2,), kwargs = {})\n",
      "    %layer2_0_downsample_0 : [num_users=1] = call_module[target=layer2.0.downsample.0](args = (%layer1_1_relu_1,), kwargs = {})\n",
      "    %layer2_0_downsample_1 : [num_users=1] = call_module[target=layer2.0.downsample.1](args = (%layer2_0_downsample_0,), kwargs = {})\n",
      "    %add_2 : [num_users=1] = call_function[target=operator.add](args = (%layer2_0_bn2, %layer2_0_downsample_1), kwargs = {})\n",
      "    %layer2_0_relu_1 : [num_users=2] = call_module[target=layer2.0.relu](args = (%add_2,), kwargs = {})\n",
      "    %layer2_1_conv1 : [num_users=1] = call_module[target=layer2.1.conv1](args = (%layer2_0_relu_1,), kwargs = {})\n",
      "    %layer2_1_bn1 : [num_users=1] = call_module[target=layer2.1.bn1](args = (%layer2_1_conv1,), kwargs = {})\n",
      "    %layer2_1_relu : [num_users=1] = call_module[target=layer2.1.relu](args = (%layer2_1_bn1,), kwargs = {})\n",
      "    %layer2_1_conv2 : [num_users=1] = call_module[target=layer2.1.conv2](args = (%layer2_1_relu,), kwargs = {})\n",
      "    %layer2_1_bn2 : [num_users=1] = call_module[target=layer2.1.bn2](args = (%layer2_1_conv2,), kwargs = {})\n",
      "    %add_3 : [num_users=1] = call_function[target=operator.add](args = (%layer2_1_bn2, %layer2_0_relu_1), kwargs = {})\n",
      "    %layer2_1_relu_1 : [num_users=2] = call_module[target=layer2.1.relu](args = (%add_3,), kwargs = {})\n",
      "    %layer3_0_conv1 : [num_users=1] = call_module[target=layer3.0.conv1](args = (%layer2_1_relu_1,), kwargs = {})\n",
      "    %layer3_0_bn1 : [num_users=1] = call_module[target=layer3.0.bn1](args = (%layer3_0_conv1,), kwargs = {})\n",
      "    %layer3_0_relu : [num_users=1] = call_module[target=layer3.0.relu](args = (%layer3_0_bn1,), kwargs = {})\n",
      "    %layer3_0_conv2 : [num_users=1] = call_module[target=layer3.0.conv2](args = (%layer3_0_relu,), kwargs = {})\n",
      "    %layer3_0_bn2 : [num_users=1] = call_module[target=layer3.0.bn2](args = (%layer3_0_conv2,), kwargs = {})\n",
      "    %layer3_0_downsample_0 : [num_users=1] = call_module[target=layer3.0.downsample.0](args = (%layer2_1_relu_1,), kwargs = {})\n",
      "    %layer3_0_downsample_1 : [num_users=1] = call_module[target=layer3.0.downsample.1](args = (%layer3_0_downsample_0,), kwargs = {})\n",
      "    %add_4 : [num_users=1] = call_function[target=operator.add](args = (%layer3_0_bn2, %layer3_0_downsample_1), kwargs = {})\n",
      "    %layer3_0_relu_1 : [num_users=2] = call_module[target=layer3.0.relu](args = (%add_4,), kwargs = {})\n",
      "    %layer3_1_conv1 : [num_users=1] = call_module[target=layer3.1.conv1](args = (%layer3_0_relu_1,), kwargs = {})\n",
      "    %layer3_1_bn1 : [num_users=1] = call_module[target=layer3.1.bn1](args = (%layer3_1_conv1,), kwargs = {})\n",
      "    %layer3_1_relu : [num_users=1] = call_module[target=layer3.1.relu](args = (%layer3_1_bn1,), kwargs = {})\n",
      "    %layer3_1_conv2 : [num_users=1] = call_module[target=layer3.1.conv2](args = (%layer3_1_relu,), kwargs = {})\n",
      "    %layer3_1_bn2 : [num_users=1] = call_module[target=layer3.1.bn2](args = (%layer3_1_conv2,), kwargs = {})\n",
      "    %add_5 : [num_users=1] = call_function[target=operator.add](args = (%layer3_1_bn2, %layer3_0_relu_1), kwargs = {})\n",
      "    %layer3_1_relu_1 : [num_users=2] = call_module[target=layer3.1.relu](args = (%add_5,), kwargs = {})\n",
      "    %layer4_0_conv1 : [num_users=1] = call_module[target=layer4.0.conv1](args = (%layer3_1_relu_1,), kwargs = {})\n",
      "    %layer4_0_bn1 : [num_users=1] = call_module[target=layer4.0.bn1](args = (%layer4_0_conv1,), kwargs = {})\n",
      "    %layer4_0_relu : [num_users=1] = call_module[target=layer4.0.relu](args = (%layer4_0_bn1,), kwargs = {})\n",
      "    %layer4_0_conv2 : [num_users=1] = call_module[target=layer4.0.conv2](args = (%layer4_0_relu,), kwargs = {})\n",
      "    %layer4_0_bn2 : [num_users=1] = call_module[target=layer4.0.bn2](args = (%layer4_0_conv2,), kwargs = {})\n",
      "    %layer4_0_downsample_0 : [num_users=1] = call_module[target=layer4.0.downsample.0](args = (%layer3_1_relu_1,), kwargs = {})\n",
      "    %layer4_0_downsample_1 : [num_users=1] = call_module[target=layer4.0.downsample.1](args = (%layer4_0_downsample_0,), kwargs = {})\n",
      "    %add_6 : [num_users=1] = call_function[target=operator.add](args = (%layer4_0_bn2, %layer4_0_downsample_1), kwargs = {})\n",
      "    %layer4_0_relu_1 : [num_users=2] = call_module[target=layer4.0.relu](args = (%add_6,), kwargs = {})\n",
      "    %layer4_1_conv1 : [num_users=1] = call_module[target=layer4.1.conv1](args = (%layer4_0_relu_1,), kwargs = {})\n",
      "    %layer4_1_bn1 : [num_users=1] = call_module[target=layer4.1.bn1](args = (%layer4_1_conv1,), kwargs = {})\n",
      "    %layer4_1_relu : [num_users=1] = call_module[target=layer4.1.relu](args = (%layer4_1_bn1,), kwargs = {})\n",
      "    %layer4_1_conv2 : [num_users=1] = call_module[target=layer4.1.conv2](args = (%layer4_1_relu,), kwargs = {})\n",
      "    %layer4_1_bn2 : [num_users=1] = call_module[target=layer4.1.bn2](args = (%layer4_1_conv2,), kwargs = {})\n",
      "    %add_7 : [num_users=1] = call_function[target=operator.add](args = (%layer4_1_bn2, %layer4_0_relu_1), kwargs = {})\n",
      "    %layer4_1_relu_1 : [num_users=1] = call_module[target=layer4.1.relu](args = (%add_7,), kwargs = {})\n",
      "    %avgpool : [num_users=1] = call_module[target=avgpool](args = (%layer4_1_relu_1,), kwargs = {})\n",
      "    %flatten : [num_users=1] = call_function[target=torch.flatten](args = (%avgpool, 1), kwargs = {})\n",
      "    %fc : [num_users=1] = call_module[target=fc](args = (%flatten,), kwargs = {})\n",
      "    return fc\n",
      "\n",
      "[print_raw_fx_graph] Print the intermediate representation (IR) with Torch.FX in a table format\n",
      "opcode         name                   target                                                      args                                   kwargs\n",
      "-------------  ---------------------  ----------------------------------------------------------  -------------------------------------  --------\n",
      "placeholder    x                      x                                                           ()                                     {}\n",
      "call_module    conv1                  conv1                                                       (x,)                                   {}\n",
      "call_module    bn1                    bn1                                                         (conv1,)                               {}\n",
      "call_module    relu                   relu                                                        (bn1,)                                 {}\n",
      "call_module    maxpool                maxpool                                                     (relu,)                                {}\n",
      "call_module    layer1_0_conv1         layer1.0.conv1                                              (maxpool,)                             {}\n",
      "call_module    layer1_0_bn1           layer1.0.bn1                                                (layer1_0_conv1,)                      {}\n",
      "call_module    layer1_0_relu          layer1.0.relu                                               (layer1_0_bn1,)                        {}\n",
      "call_module    layer1_0_conv2         layer1.0.conv2                                              (layer1_0_relu,)                       {}\n",
      "call_module    layer1_0_bn2           layer1.0.bn2                                                (layer1_0_conv2,)                      {}\n",
      "call_function  add                    <built-in function add>                                     (layer1_0_bn2, maxpool)                {}\n",
      "call_module    layer1_0_relu_1        layer1.0.relu                                               (add,)                                 {}\n",
      "call_module    layer1_1_conv1         layer1.1.conv1                                              (layer1_0_relu_1,)                     {}\n",
      "call_module    layer1_1_bn1           layer1.1.bn1                                                (layer1_1_conv1,)                      {}\n",
      "call_module    layer1_1_relu          layer1.1.relu                                               (layer1_1_bn1,)                        {}\n",
      "call_module    layer1_1_conv2         layer1.1.conv2                                              (layer1_1_relu,)                       {}\n",
      "call_module    layer1_1_bn2           layer1.1.bn2                                                (layer1_1_conv2,)                      {}\n",
      "call_function  add_1                  <built-in function add>                                     (layer1_1_bn2, layer1_0_relu_1)        {}\n",
      "call_module    layer1_1_relu_1        layer1.1.relu                                               (add_1,)                               {}\n",
      "call_module    layer2_0_conv1         layer2.0.conv1                                              (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_bn1           layer2.0.bn1                                                (layer2_0_conv1,)                      {}\n",
      "call_module    layer2_0_relu          layer2.0.relu                                               (layer2_0_bn1,)                        {}\n",
      "call_module    layer2_0_conv2         layer2.0.conv2                                              (layer2_0_relu,)                       {}\n",
      "call_module    layer2_0_bn2           layer2.0.bn2                                                (layer2_0_conv2,)                      {}\n",
      "call_module    layer2_0_downsample_0  layer2.0.downsample.0                                       (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_downsample_1  layer2.0.downsample.1                                       (layer2_0_downsample_0,)               {}\n",
      "call_function  add_2                  <built-in function add>                                     (layer2_0_bn2, layer2_0_downsample_1)  {}\n",
      "call_module    layer2_0_relu_1        layer2.0.relu                                               (add_2,)                               {}\n",
      "call_module    layer2_1_conv1         layer2.1.conv1                                              (layer2_0_relu_1,)                     {}\n",
      "call_module    layer2_1_bn1           layer2.1.bn1                                                (layer2_1_conv1,)                      {}\n",
      "call_module    layer2_1_relu          layer2.1.relu                                               (layer2_1_bn1,)                        {}\n",
      "call_module    layer2_1_conv2         layer2.1.conv2                                              (layer2_1_relu,)                       {}\n",
      "call_module    layer2_1_bn2           layer2.1.bn2                                                (layer2_1_conv2,)                      {}\n",
      "call_function  add_3                  <built-in function add>                                     (layer2_1_bn2, layer2_0_relu_1)        {}\n",
      "call_module    layer2_1_relu_1        layer2.1.relu                                               (add_3,)                               {}\n",
      "call_module    layer3_0_conv1         layer3.0.conv1                                              (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_bn1           layer3.0.bn1                                                (layer3_0_conv1,)                      {}\n",
      "call_module    layer3_0_relu          layer3.0.relu                                               (layer3_0_bn1,)                        {}\n",
      "call_module    layer3_0_conv2         layer3.0.conv2                                              (layer3_0_relu,)                       {}\n",
      "call_module    layer3_0_bn2           layer3.0.bn2                                                (layer3_0_conv2,)                      {}\n",
      "call_module    layer3_0_downsample_0  layer3.0.downsample.0                                       (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_downsample_1  layer3.0.downsample.1                                       (layer3_0_downsample_0,)               {}\n",
      "call_function  add_4                  <built-in function add>                                     (layer3_0_bn2, layer3_0_downsample_1)  {}\n",
      "call_module    layer3_0_relu_1        layer3.0.relu                                               (add_4,)                               {}\n",
      "call_module    layer3_1_conv1         layer3.1.conv1                                              (layer3_0_relu_1,)                     {}\n",
      "call_module    layer3_1_bn1           layer3.1.bn1                                                (layer3_1_conv1,)                      {}\n",
      "call_module    layer3_1_relu          layer3.1.relu                                               (layer3_1_bn1,)                        {}\n",
      "call_module    layer3_1_conv2         layer3.1.conv2                                              (layer3_1_relu,)                       {}\n",
      "call_module    layer3_1_bn2           layer3.1.bn2                                                (layer3_1_conv2,)                      {}\n",
      "call_function  add_5                  <built-in function add>                                     (layer3_1_bn2, layer3_0_relu_1)        {}\n",
      "call_module    layer3_1_relu_1        layer3.1.relu                                               (add_5,)                               {}\n",
      "call_module    layer4_0_conv1         layer4.0.conv1                                              (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_bn1           layer4.0.bn1                                                (layer4_0_conv1,)                      {}\n",
      "call_module    layer4_0_relu          layer4.0.relu                                               (layer4_0_bn1,)                        {}\n",
      "call_module    layer4_0_conv2         layer4.0.conv2                                              (layer4_0_relu,)                       {}\n",
      "call_module    layer4_0_bn2           layer4.0.bn2                                                (layer4_0_conv2,)                      {}\n",
      "call_module    layer4_0_downsample_0  layer4.0.downsample.0                                       (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_downsample_1  layer4.0.downsample.1                                       (layer4_0_downsample_0,)               {}\n",
      "call_function  add_6                  <built-in function add>                                     (layer4_0_bn2, layer4_0_downsample_1)  {}\n",
      "call_module    layer4_0_relu_1        layer4.0.relu                                               (add_6,)                               {}\n",
      "call_module    layer4_1_conv1         layer4.1.conv1                                              (layer4_0_relu_1,)                     {}\n",
      "call_module    layer4_1_bn1           layer4.1.bn1                                                (layer4_1_conv1,)                      {}\n",
      "call_module    layer4_1_relu          layer4.1.relu                                               (layer4_1_bn1,)                        {}\n",
      "call_module    layer4_1_conv2         layer4.1.conv2                                              (layer4_1_relu,)                       {}\n",
      "call_module    layer4_1_bn2           layer4.1.bn2                                                (layer4_1_conv2,)                      {}\n",
      "call_function  add_7                  <built-in function add>                                     (layer4_1_bn2, layer4_0_relu_1)        {}\n",
      "call_module    layer4_1_relu_1        layer4.1.relu                                               (add_7,)                               {}\n",
      "call_module    avgpool                avgpool                                                     (layer4_1_relu_1,)                     {}\n",
      "call_function  flatten                <built-in method flatten of type object at 0x73c311d84480>  (avgpool, 1)                           {}\n",
      "call_module    fc                     fc                                                          (flatten,)                             {}\n",
      "output         output                 output                                                      (fc,)                                  {}\n",
      "\n",
      "[build_fx_graph] Build the module name and type dictionary\n",
      "[build_fx_graph] module_name: , module type: <class 'torchvision.models.resnet.ResNet'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: maxpool, module type: <class 'torch.nn.modules.pooling.MaxPool2d'>\n",
      "[build_fx_graph] module_name: layer1, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer1.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer1.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer1.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer1.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer1.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer1.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer1.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer2.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer2.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer2.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer2.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer2.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer2.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer2.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer2.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer3.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer3.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer3.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer3.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer3.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer3.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer3.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer3.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer4.0, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer4.0.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.0.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer4.0.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.0.downsample, module type: <class 'torch.nn.modules.container.Sequential'>\n",
      "[build_fx_graph] module_name: layer4.0.downsample.0, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.0.downsample.1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.1, module type: <class 'torchvision.models.resnet.BasicBlock'>\n",
      "[build_fx_graph] module_name: layer4.1.conv1, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.1.bn1, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: layer4.1.relu, module type: <class 'torch.nn.modules.activation.ReLU'>\n",
      "[build_fx_graph] module_name: layer4.1.conv2, module type: <class 'torch.nn.modules.conv.Conv2d'>\n",
      "[build_fx_graph] this module has 'group' param with value: 1\n",
      "[build_fx_graph] module_name: layer4.1.bn2, module type: <class 'torch.nn.modules.batchnorm.BatchNorm2d'>\n",
      "[build_fx_graph] module_name: avgpool, module type: <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>\n",
      "[build_fx_graph] module_name: fc, module type: <class 'torch.nn.modules.linear.Linear'>\n",
      "\n",
      "[build_fx_graph] Print the children and parents relationship for each layer\n",
      "[build_fx_graph] This is the 'input' node: x\n",
      "[build_fx_graph] This is the 'call_module' node: conv1, its parent list: ['x'], its children list: ['bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: bn1, its parent list: ['conv1'], its children list: ['relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: relu, its parent list: ['bn1'], its children list: ['maxpool'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: maxpool, its parent list: ['relu'], its children list: ['layer1.0.conv1', 'add'], its type: torch.nn.modules.pooling.MaxPool2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.conv1, its parent list: ['maxpool'], its children list: ['layer1.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.bn1, its parent list: ['layer1.0.conv1'], its children list: ['layer1.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.relu, its parent list: ['layer1.0.bn1'], its children list: ['layer1.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.conv2, its parent list: ['layer1.0.relu'], its children list: ['layer1.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.bn2, its parent list: ['layer1.0.conv2'], its children list: ['add'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add, its parent list: ['layer1.0.bn2', 'maxpool'], its children list: ['layer1.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer1.0.relu', the manually converted node name is 'layer1.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.0.relu.1, its parent list: ['add'], its children list: ['layer1.1.conv1', 'add.1'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.conv1, its parent list: ['layer1.0.relu.1'], its children list: ['layer1.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.bn1, its parent list: ['layer1.1.conv1'], its children list: ['layer1.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.relu, its parent list: ['layer1.1.bn1'], its children list: ['layer1.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.conv2, its parent list: ['layer1.1.relu'], its children list: ['layer1.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.bn2, its parent list: ['layer1.1.conv2'], its children list: ['add.1'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.1, its parent list: ['layer1.1.bn2', 'layer1.0.relu.1'], its children list: ['layer1.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer1.1.relu', the manually converted node name is 'layer1.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer1.1.relu.1, its parent list: ['add.1'], its children list: ['layer2.0.conv1', 'layer2.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.conv1, its parent list: ['layer1.1.relu.1'], its children list: ['layer2.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.bn1, its parent list: ['layer2.0.conv1'], its children list: ['layer2.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.relu, its parent list: ['layer2.0.bn1'], its children list: ['layer2.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.conv2, its parent list: ['layer2.0.relu'], its children list: ['layer2.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.bn2, its parent list: ['layer2.0.conv2'], its children list: ['add.2'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.downsample.0, its parent list: ['layer1.1.relu.1'], its children list: ['layer2.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.downsample.1, its parent list: ['layer2.0.downsample.0'], its children list: ['add.2'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.2, its parent list: ['layer2.0.bn2', 'layer2.0.downsample.1'], its children list: ['layer2.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer2.0.relu', the manually converted node name is 'layer2.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.0.relu.1, its parent list: ['add.2'], its children list: ['layer2.1.conv1', 'add.3'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.conv1, its parent list: ['layer2.0.relu.1'], its children list: ['layer2.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.bn1, its parent list: ['layer2.1.conv1'], its children list: ['layer2.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.relu, its parent list: ['layer2.1.bn1'], its children list: ['layer2.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.conv2, its parent list: ['layer2.1.relu'], its children list: ['layer2.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.bn2, its parent list: ['layer2.1.conv2'], its children list: ['add.3'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.3, its parent list: ['layer2.1.bn2', 'layer2.0.relu.1'], its children list: ['layer2.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer2.1.relu', the manually converted node name is 'layer2.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer2.1.relu.1, its parent list: ['add.3'], its children list: ['layer3.0.conv1', 'layer3.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.conv1, its parent list: ['layer2.1.relu.1'], its children list: ['layer3.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.bn1, its parent list: ['layer3.0.conv1'], its children list: ['layer3.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.relu, its parent list: ['layer3.0.bn1'], its children list: ['layer3.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.conv2, its parent list: ['layer3.0.relu'], its children list: ['layer3.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.bn2, its parent list: ['layer3.0.conv2'], its children list: ['add.4'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.downsample.0, its parent list: ['layer2.1.relu.1'], its children list: ['layer3.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.downsample.1, its parent list: ['layer3.0.downsample.0'], its children list: ['add.4'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.4, its parent list: ['layer3.0.bn2', 'layer3.0.downsample.1'], its children list: ['layer3.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer3.0.relu', the manually converted node name is 'layer3.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.0.relu.1, its parent list: ['add.4'], its children list: ['layer3.1.conv1', 'add.5'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.conv1, its parent list: ['layer3.0.relu.1'], its children list: ['layer3.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.bn1, its parent list: ['layer3.1.conv1'], its children list: ['layer3.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.relu, its parent list: ['layer3.1.bn1'], its children list: ['layer3.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.conv2, its parent list: ['layer3.1.relu'], its children list: ['layer3.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.bn2, its parent list: ['layer3.1.conv2'], its children list: ['add.5'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.5, its parent list: ['layer3.1.bn2', 'layer3.0.relu.1'], its children list: ['layer3.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer3.1.relu', the manually converted node name is 'layer3.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer3.1.relu.1, its parent list: ['add.5'], its children list: ['layer4.0.conv1', 'layer4.0.downsample.0'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.conv1, its parent list: ['layer3.1.relu.1'], its children list: ['layer4.0.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.bn1, its parent list: ['layer4.0.conv1'], its children list: ['layer4.0.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.relu, its parent list: ['layer4.0.bn1'], its children list: ['layer4.0.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.conv2, its parent list: ['layer4.0.relu'], its children list: ['layer4.0.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.bn2, its parent list: ['layer4.0.conv2'], its children list: ['add.6'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.downsample.0, its parent list: ['layer3.1.relu.1'], its children list: ['layer4.0.downsample.1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.downsample.1, its parent list: ['layer4.0.downsample.0'], its children list: ['add.6'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.6, its parent list: ['layer4.0.bn2', 'layer4.0.downsample.1'], its children list: ['layer4.0.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer4.0.relu', the manually converted node name is 'layer4.0.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.0.relu.1, its parent list: ['add.6'], its children list: ['layer4.1.conv1', 'add.7'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.conv1, its parent list: ['layer4.0.relu.1'], its children list: ['layer4.1.bn1'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.bn1, its parent list: ['layer4.1.conv1'], its children list: ['layer4.1.relu'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.relu, its parent list: ['layer4.1.bn1'], its children list: ['layer4.1.conv2'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.conv2, its parent list: ['layer4.1.relu'], its children list: ['layer4.1.bn2'], its type: torch.nn.modules.conv.Conv2d\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.bn2, its parent list: ['layer4.1.conv2'], its children list: ['add.7'], its type: torch.nn.modules.batchnorm.BatchNorm2d\n",
      "[build_fx_graph] This is the 'call_function' node: add.7, its parent list: ['layer4.1.bn2', 'layer4.0.relu.1'], its children list: ['layer4.1.relu.1']\n",
      "[build_fx_graph][warning] The target name from Torch.FX is 'layer4.1.relu', the manually converted node name is 'layer4.1.relu.1', not the same one, choose the converted node name\n",
      "[build_fx_graph] This is the 'call_module' node: layer4.1.relu.1, its parent list: ['add.7'], its children list: ['avgpool'], its type: torch.nn.modules.activation.ReLU\n",
      "[build_fx_graph] This is the 'call_module' node: avgpool, its parent list: ['layer4.1.relu.1'], its children list: ['flatten'], its type: torch.nn.modules.pooling.AdaptiveAvgPool2d\n",
      "[build_fx_graph] This is the 'call_function' node: flatten, its parent list: ['avgpool'], its children list: ['fc']\n",
      "[build_fx_graph] This is the 'call_module' node: fc, its parent list: ['flatten'], its children list: ['output'], its type: torch.nn.modules.linear.Linear\n",
      "[build_fx_graph] This is the 'output' node: output\n",
      "\n",
      "[init_permutation_flags] Initialize the permutation flags for each node according to module type and parameters\n",
      "Initializing node conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['x'], 'children': ['bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '3', 'K_param': '64'}\n",
      "\tInitialized node conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['x'], 'children': ['bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '3', 'K_param': '64', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['conv1'], 'children': ['relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['conv1'], 'children': ['relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node relu of type torch.nn.modules.activation.ReLU: {'parents': ['bn1'], 'children': ['maxpool'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node relu of type torch.nn.modules.activation.ReLU: {'parents': ['bn1'], 'children': ['maxpool'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node maxpool of type torch.nn.modules.pooling.MaxPool2d: {'parents': ['relu'], 'children': ['layer1.0.conv1', 'add'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.pooling.MaxPool2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node maxpool of type torch.nn.modules.pooling.MaxPool2d: {'parents': ['relu'], 'children': ['layer1.0.conv1', 'add'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.pooling.MaxPool2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['maxpool'], 'children': ['layer1.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64'}\n",
      "\tInitialized node layer1.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['maxpool'], 'children': ['layer1.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.0.conv1'], 'children': ['layer1.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.0.conv1'], 'children': ['layer1.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer1.0.bn1'], 'children': ['layer1.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer1.0.bn1'], 'children': ['layer1.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.0.relu'], 'children': ['layer1.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64'}\n",
      "\tInitialized node layer1.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.0.relu'], 'children': ['layer1.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.0.conv2'], 'children': ['add'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.0.conv2'], 'children': ['add'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add of type None: {'parents': ['layer1.0.bn2', 'maxpool'], 'children': ['layer1.0.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add of type None: {'parents': ['layer1.0.bn2', 'maxpool'], 'children': ['layer1.0.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer1.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add'], 'children': ['layer1.1.conv1', 'add.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add'], 'children': ['layer1.1.conv1', 'add.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.0.relu.1'], 'children': ['layer1.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64'}\n",
      "\tInitialized node layer1.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.0.relu.1'], 'children': ['layer1.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.1.conv1'], 'children': ['layer1.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.1.conv1'], 'children': ['layer1.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer1.1.bn1'], 'children': ['layer1.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer1.1.bn1'], 'children': ['layer1.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu'], 'children': ['layer1.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64'}\n",
      "\tInitialized node layer1.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu'], 'children': ['layer1.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '64', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer1.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.1.conv2'], 'children': ['add.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer1.1.conv2'], 'children': ['add.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.1 of type None: {'parents': ['layer1.1.bn2', 'layer1.0.relu.1'], 'children': ['layer1.1.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.1 of type None: {'parents': ['layer1.1.bn2', 'layer1.0.relu.1'], 'children': ['layer1.1.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer1.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.1'], 'children': ['layer2.0.conv1', 'layer2.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer1.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.1'], 'children': ['layer2.0.conv1', 'layer2.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu.1'], 'children': ['layer2.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '128'}\n",
      "\tInitialized node layer2.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu.1'], 'children': ['layer2.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '128', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.conv1'], 'children': ['layer2.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.conv1'], 'children': ['layer2.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer2.0.bn1'], 'children': ['layer2.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer2.0.bn1'], 'children': ['layer2.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.0.relu'], 'children': ['layer2.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128'}\n",
      "\tInitialized node layer2.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.0.relu'], 'children': ['layer2.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.conv2'], 'children': ['add.2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.conv2'], 'children': ['add.2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu.1'], 'children': ['layer2.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '128'}\n",
      "\tInitialized node layer2.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer1.1.relu.1'], 'children': ['layer2.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '64', 'K_param': '128', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.downsample.0'], 'children': ['add.2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.0.downsample.0'], 'children': ['add.2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.2 of type None: {'parents': ['layer2.0.bn2', 'layer2.0.downsample.1'], 'children': ['layer2.0.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.2 of type None: {'parents': ['layer2.0.bn2', 'layer2.0.downsample.1'], 'children': ['layer2.0.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer2.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.2'], 'children': ['layer2.1.conv1', 'add.3'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.2'], 'children': ['layer2.1.conv1', 'add.3'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.0.relu.1'], 'children': ['layer2.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128'}\n",
      "\tInitialized node layer2.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.0.relu.1'], 'children': ['layer2.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.1.conv1'], 'children': ['layer2.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.1.conv1'], 'children': ['layer2.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer2.1.bn1'], 'children': ['layer2.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer2.1.bn1'], 'children': ['layer2.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu'], 'children': ['layer2.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128'}\n",
      "\tInitialized node layer2.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu'], 'children': ['layer2.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '128', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer2.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.1.conv2'], 'children': ['add.3'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer2.1.conv2'], 'children': ['add.3'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.3 of type None: {'parents': ['layer2.1.bn2', 'layer2.0.relu.1'], 'children': ['layer2.1.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.3 of type None: {'parents': ['layer2.1.bn2', 'layer2.0.relu.1'], 'children': ['layer2.1.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer2.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.3'], 'children': ['layer3.0.conv1', 'layer3.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer2.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.3'], 'children': ['layer3.0.conv1', 'layer3.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu.1'], 'children': ['layer3.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '256'}\n",
      "\tInitialized node layer3.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu.1'], 'children': ['layer3.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '256', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.conv1'], 'children': ['layer3.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.conv1'], 'children': ['layer3.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer3.0.bn1'], 'children': ['layer3.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer3.0.bn1'], 'children': ['layer3.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.0.relu'], 'children': ['layer3.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256'}\n",
      "\tInitialized node layer3.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.0.relu'], 'children': ['layer3.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.conv2'], 'children': ['add.4'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.conv2'], 'children': ['add.4'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu.1'], 'children': ['layer3.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '256'}\n",
      "\tInitialized node layer3.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer2.1.relu.1'], 'children': ['layer3.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '128', 'K_param': '256', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.downsample.0'], 'children': ['add.4'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.0.downsample.0'], 'children': ['add.4'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.4 of type None: {'parents': ['layer3.0.bn2', 'layer3.0.downsample.1'], 'children': ['layer3.0.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.4 of type None: {'parents': ['layer3.0.bn2', 'layer3.0.downsample.1'], 'children': ['layer3.0.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer3.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.4'], 'children': ['layer3.1.conv1', 'add.5'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.4'], 'children': ['layer3.1.conv1', 'add.5'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.0.relu.1'], 'children': ['layer3.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256'}\n",
      "\tInitialized node layer3.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.0.relu.1'], 'children': ['layer3.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.1.conv1'], 'children': ['layer3.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.1.conv1'], 'children': ['layer3.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer3.1.bn1'], 'children': ['layer3.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer3.1.bn1'], 'children': ['layer3.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu'], 'children': ['layer3.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256'}\n",
      "\tInitialized node layer3.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu'], 'children': ['layer3.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '256', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer3.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.1.conv2'], 'children': ['add.5'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer3.1.conv2'], 'children': ['add.5'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.5 of type None: {'parents': ['layer3.1.bn2', 'layer3.0.relu.1'], 'children': ['layer3.1.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.5 of type None: {'parents': ['layer3.1.bn2', 'layer3.0.relu.1'], 'children': ['layer3.1.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer3.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.5'], 'children': ['layer4.0.conv1', 'layer4.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer3.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.5'], 'children': ['layer4.0.conv1', 'layer4.0.downsample.0'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu.1'], 'children': ['layer4.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '512'}\n",
      "\tInitialized node layer4.0.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu.1'], 'children': ['layer4.0.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '512', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.conv1'], 'children': ['layer4.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.0.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.conv1'], 'children': ['layer4.0.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer4.0.bn1'], 'children': ['layer4.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.0.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer4.0.bn1'], 'children': ['layer4.0.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.0.relu'], 'children': ['layer4.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512'}\n",
      "\tInitialized node layer4.0.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.0.relu'], 'children': ['layer4.0.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.conv2'], 'children': ['add.6'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.0.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.conv2'], 'children': ['add.6'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu.1'], 'children': ['layer4.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '512'}\n",
      "\tInitialized node layer4.0.downsample.0 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer3.1.relu.1'], 'children': ['layer4.0.downsample.1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '256', 'K_param': '512', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.downsample.0'], 'children': ['add.6'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.0.downsample.1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.0.downsample.0'], 'children': ['add.6'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.6 of type None: {'parents': ['layer4.0.bn2', 'layer4.0.downsample.1'], 'children': ['layer4.0.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.6 of type None: {'parents': ['layer4.0.bn2', 'layer4.0.downsample.1'], 'children': ['layer4.0.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer4.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.6'], 'children': ['layer4.1.conv1', 'add.7'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.0.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.6'], 'children': ['layer4.1.conv1', 'add.7'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.0.relu.1'], 'children': ['layer4.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512'}\n",
      "\tInitialized node layer4.1.conv1 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.0.relu.1'], 'children': ['layer4.1.bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.1.conv1'], 'children': ['layer4.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.1.bn1 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.1.conv1'], 'children': ['layer4.1.relu'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer4.1.bn1'], 'children': ['layer4.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.1.relu of type torch.nn.modules.activation.ReLU: {'parents': ['layer4.1.bn1'], 'children': ['layer4.1.conv2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.1.relu'], 'children': ['layer4.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512'}\n",
      "\tInitialized node layer4.1.conv2 of type torch.nn.modules.conv.Conv2d: {'parents': ['layer4.1.relu'], 'children': ['layer4.1.bn2'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '512', 'K_param': '512', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node layer4.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.1.conv2'], 'children': ['add.7'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.1.bn2 of type torch.nn.modules.batchnorm.BatchNorm2d: {'parents': ['layer4.1.conv2'], 'children': ['add.7'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.batchnorm.BatchNorm2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': True, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node add.7 of type None: {'parents': ['layer4.1.bn2', 'layer4.0.relu.1'], 'children': ['layer4.1.relu.1'], 'fx_op': 'call_function'}\n",
      "\tInitialized node add.7 of type None: {'parents': ['layer4.1.bn2', 'layer4.0.relu.1'], 'children': ['layer4.1.relu.1'], 'fx_op': 'call_function'}\n",
      "Initializing node layer4.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.7'], 'children': ['avgpool'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node layer4.1.relu.1 of type torch.nn.modules.activation.ReLU: {'parents': ['add.7'], 'children': ['avgpool'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.activation.ReLU', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node avgpool of type torch.nn.modules.pooling.AdaptiveAvgPool2d: {'parents': ['layer4.1.relu.1'], 'children': ['flatten'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None'}\n",
      "\tInitialized node avgpool of type torch.nn.modules.pooling.AdaptiveAvgPool2d: {'parents': ['layer4.1.relu.1'], 'children': ['flatten'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.pooling.AdaptiveAvgPool2d', 'groups_param': 'None', 'C_param': 'None', 'K_param': 'None', 'C_permutable': False, 'K_permutable': False, 'K_passthru': True, 'is_real': False, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "Initializing node flatten of type None: {'parents': ['avgpool'], 'children': ['fc'], 'fx_op': 'call_function'}\n",
      "\tInitialized node flatten of type None: {'parents': ['avgpool'], 'children': ['fc'], 'fx_op': 'call_function'}\n",
      "Initializing node fc of type torch.nn.modules.linear.Linear: {'parents': ['flatten'], 'children': ['output'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.linear.Linear', 'groups_param': 'None', 'C_param': '512', 'K_param': '10'}\n",
      "\tInitialized node fc of type torch.nn.modules.linear.Linear: {'parents': ['flatten'], 'children': ['output'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.linear.Linear', 'groups_param': 'None', 'C_param': '512', 'K_param': '10', 'C_permutable': True, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': None, 'coparent_group_id': None}\n",
      "\n",
      "[find_real_parents] Find the real parents for each node according to the whole network graph built with Torch.FX\n",
      "[find_real_parents] conv1 has 0 real parents: set()\n",
      "\tchecking parent conv1 of node bn1\n",
      "[find_real_parents] bn1 has 1 real parents: {'conv1'}\n",
      "\tchecking parent bn1 of node relu\n",
      "[find_real_parents] relu has 1 real parents: {'conv1'}\n",
      "\tchecking parent relu of node maxpool\n",
      "[find_real_parents] maxpool has 1 real parents: {'conv1'}\n",
      "\tchecking parent maxpool of node layer1.0.conv1\n",
      "[find_real_parents] layer1.0.conv1 has 1 real parents: {'conv1'}\n",
      "\tchecking parent layer1.0.conv1 of node layer1.0.bn1\n",
      "[find_real_parents] layer1.0.bn1 has 1 real parents: {'layer1.0.conv1'}\n",
      "\tchecking parent layer1.0.bn1 of node layer1.0.relu\n",
      "[find_real_parents] layer1.0.relu has 1 real parents: {'layer1.0.conv1'}\n",
      "\tchecking parent layer1.0.relu of node layer1.0.conv2\n",
      "[find_real_parents] layer1.0.conv2 has 1 real parents: {'layer1.0.conv1'}\n",
      "\tchecking parent layer1.0.conv2 of node layer1.0.bn2\n",
      "[find_real_parents] layer1.0.bn2 has 1 real parents: {'layer1.0.conv2'}\n",
      "\tchecking parent layer1.0.bn2 of node add\n",
      "\tchecking parent maxpool of node add\n",
      "[find_real_parents] add has 2 real parents: {'layer1.0.conv2', 'conv1'}\n",
      "\tchecking parent add of node layer1.0.relu.1\n",
      "[find_real_parents] layer1.0.relu.1 has 2 real parents: {'layer1.0.conv2', 'conv1'}\n",
      "\tchecking parent layer1.0.relu.1 of node layer1.1.conv1\n",
      "[find_real_parents] layer1.1.conv1 has 2 real parents: {'layer1.0.conv2', 'conv1'}\n",
      "\tchecking parent layer1.1.conv1 of node layer1.1.bn1\n",
      "[find_real_parents] layer1.1.bn1 has 1 real parents: {'layer1.1.conv1'}\n",
      "\tchecking parent layer1.1.bn1 of node layer1.1.relu\n",
      "[find_real_parents] layer1.1.relu has 1 real parents: {'layer1.1.conv1'}\n",
      "\tchecking parent layer1.1.relu of node layer1.1.conv2\n",
      "[find_real_parents] layer1.1.conv2 has 1 real parents: {'layer1.1.conv1'}\n",
      "\tchecking parent layer1.1.conv2 of node layer1.1.bn2\n",
      "[find_real_parents] layer1.1.bn2 has 1 real parents: {'layer1.1.conv2'}\n",
      "\tchecking parent layer1.1.bn2 of node add.1\n",
      "\tchecking parent layer1.0.relu.1 of node add.1\n",
      "[find_real_parents] add.1 has 3 real parents: {'layer1.0.conv2', 'layer1.1.conv2', 'conv1'}\n",
      "\tchecking parent add.1 of node layer1.1.relu.1\n",
      "[find_real_parents] layer1.1.relu.1 has 3 real parents: {'layer1.0.conv2', 'layer1.1.conv2', 'conv1'}\n",
      "\tchecking parent layer1.1.relu.1 of node layer2.0.conv1\n",
      "[find_real_parents] layer2.0.conv1 has 3 real parents: {'layer1.0.conv2', 'layer1.1.conv2', 'conv1'}\n",
      "\tchecking parent layer2.0.conv1 of node layer2.0.bn1\n",
      "[find_real_parents] layer2.0.bn1 has 1 real parents: {'layer2.0.conv1'}\n",
      "\tchecking parent layer2.0.bn1 of node layer2.0.relu\n",
      "[find_real_parents] layer2.0.relu has 1 real parents: {'layer2.0.conv1'}\n",
      "\tchecking parent layer2.0.relu of node layer2.0.conv2\n",
      "[find_real_parents] layer2.0.conv2 has 1 real parents: {'layer2.0.conv1'}\n",
      "\tchecking parent layer2.0.conv2 of node layer2.0.bn2\n",
      "[find_real_parents] layer2.0.bn2 has 1 real parents: {'layer2.0.conv2'}\n",
      "\tchecking parent layer1.1.relu.1 of node layer2.0.downsample.0\n",
      "[find_real_parents] layer2.0.downsample.0 has 3 real parents: {'layer1.0.conv2', 'layer1.1.conv2', 'conv1'}\n",
      "\tchecking parent layer2.0.downsample.0 of node layer2.0.downsample.1\n",
      "[find_real_parents] layer2.0.downsample.1 has 1 real parents: {'layer2.0.downsample.0'}\n",
      "\tchecking parent layer2.0.bn2 of node add.2\n",
      "\tchecking parent layer2.0.downsample.1 of node add.2\n",
      "[find_real_parents] add.2 has 2 real parents: {'layer2.0.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent add.2 of node layer2.0.relu.1\n",
      "[find_real_parents] layer2.0.relu.1 has 2 real parents: {'layer2.0.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent layer2.0.relu.1 of node layer2.1.conv1\n",
      "[find_real_parents] layer2.1.conv1 has 2 real parents: {'layer2.0.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent layer2.1.conv1 of node layer2.1.bn1\n",
      "[find_real_parents] layer2.1.bn1 has 1 real parents: {'layer2.1.conv1'}\n",
      "\tchecking parent layer2.1.bn1 of node layer2.1.relu\n",
      "[find_real_parents] layer2.1.relu has 1 real parents: {'layer2.1.conv1'}\n",
      "\tchecking parent layer2.1.relu of node layer2.1.conv2\n",
      "[find_real_parents] layer2.1.conv2 has 1 real parents: {'layer2.1.conv1'}\n",
      "\tchecking parent layer2.1.conv2 of node layer2.1.bn2\n",
      "[find_real_parents] layer2.1.bn2 has 1 real parents: {'layer2.1.conv2'}\n",
      "\tchecking parent layer2.1.bn2 of node add.3\n",
      "\tchecking parent layer2.0.relu.1 of node add.3\n",
      "[find_real_parents] add.3 has 3 real parents: {'layer2.0.conv2', 'layer2.1.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent add.3 of node layer2.1.relu.1\n",
      "[find_real_parents] layer2.1.relu.1 has 3 real parents: {'layer2.0.conv2', 'layer2.1.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent layer2.1.relu.1 of node layer3.0.conv1\n",
      "[find_real_parents] layer3.0.conv1 has 3 real parents: {'layer2.0.conv2', 'layer2.1.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent layer3.0.conv1 of node layer3.0.bn1\n",
      "[find_real_parents] layer3.0.bn1 has 1 real parents: {'layer3.0.conv1'}\n",
      "\tchecking parent layer3.0.bn1 of node layer3.0.relu\n",
      "[find_real_parents] layer3.0.relu has 1 real parents: {'layer3.0.conv1'}\n",
      "\tchecking parent layer3.0.relu of node layer3.0.conv2\n",
      "[find_real_parents] layer3.0.conv2 has 1 real parents: {'layer3.0.conv1'}\n",
      "\tchecking parent layer3.0.conv2 of node layer3.0.bn2\n",
      "[find_real_parents] layer3.0.bn2 has 1 real parents: {'layer3.0.conv2'}\n",
      "\tchecking parent layer2.1.relu.1 of node layer3.0.downsample.0\n",
      "[find_real_parents] layer3.0.downsample.0 has 3 real parents: {'layer2.0.conv2', 'layer2.1.conv2', 'layer2.0.downsample.0'}\n",
      "\tchecking parent layer3.0.downsample.0 of node layer3.0.downsample.1\n",
      "[find_real_parents] layer3.0.downsample.1 has 1 real parents: {'layer3.0.downsample.0'}\n",
      "\tchecking parent layer3.0.bn2 of node add.4\n",
      "\tchecking parent layer3.0.downsample.1 of node add.4\n",
      "[find_real_parents] add.4 has 2 real parents: {'layer3.0.downsample.0', 'layer3.0.conv2'}\n",
      "\tchecking parent add.4 of node layer3.0.relu.1\n",
      "[find_real_parents] layer3.0.relu.1 has 2 real parents: {'layer3.0.downsample.0', 'layer3.0.conv2'}\n",
      "\tchecking parent layer3.0.relu.1 of node layer3.1.conv1\n",
      "[find_real_parents] layer3.1.conv1 has 2 real parents: {'layer3.0.downsample.0', 'layer3.0.conv2'}\n",
      "\tchecking parent layer3.1.conv1 of node layer3.1.bn1\n",
      "[find_real_parents] layer3.1.bn1 has 1 real parents: {'layer3.1.conv1'}\n",
      "\tchecking parent layer3.1.bn1 of node layer3.1.relu\n",
      "[find_real_parents] layer3.1.relu has 1 real parents: {'layer3.1.conv1'}\n",
      "\tchecking parent layer3.1.relu of node layer3.1.conv2\n",
      "[find_real_parents] layer3.1.conv2 has 1 real parents: {'layer3.1.conv1'}\n",
      "\tchecking parent layer3.1.conv2 of node layer3.1.bn2\n",
      "[find_real_parents] layer3.1.bn2 has 1 real parents: {'layer3.1.conv2'}\n",
      "\tchecking parent layer3.1.bn2 of node add.5\n",
      "\tchecking parent layer3.0.relu.1 of node add.5\n",
      "[find_real_parents] add.5 has 3 real parents: {'layer3.0.downsample.0', 'layer3.1.conv2', 'layer3.0.conv2'}\n",
      "\tchecking parent add.5 of node layer3.1.relu.1\n",
      "[find_real_parents] layer3.1.relu.1 has 3 real parents: {'layer3.0.downsample.0', 'layer3.1.conv2', 'layer3.0.conv2'}\n",
      "\tchecking parent layer3.1.relu.1 of node layer4.0.conv1\n",
      "[find_real_parents] layer4.0.conv1 has 3 real parents: {'layer3.0.downsample.0', 'layer3.1.conv2', 'layer3.0.conv2'}\n",
      "\tchecking parent layer4.0.conv1 of node layer4.0.bn1\n",
      "[find_real_parents] layer4.0.bn1 has 1 real parents: {'layer4.0.conv1'}\n",
      "\tchecking parent layer4.0.bn1 of node layer4.0.relu\n",
      "[find_real_parents] layer4.0.relu has 1 real parents: {'layer4.0.conv1'}\n",
      "\tchecking parent layer4.0.relu of node layer4.0.conv2\n",
      "[find_real_parents] layer4.0.conv2 has 1 real parents: {'layer4.0.conv1'}\n",
      "\tchecking parent layer4.0.conv2 of node layer4.0.bn2\n",
      "[find_real_parents] layer4.0.bn2 has 1 real parents: {'layer4.0.conv2'}\n",
      "\tchecking parent layer3.1.relu.1 of node layer4.0.downsample.0\n",
      "[find_real_parents] layer4.0.downsample.0 has 3 real parents: {'layer3.0.downsample.0', 'layer3.1.conv2', 'layer3.0.conv2'}\n",
      "\tchecking parent layer4.0.downsample.0 of node layer4.0.downsample.1\n",
      "[find_real_parents] layer4.0.downsample.1 has 1 real parents: {'layer4.0.downsample.0'}\n",
      "\tchecking parent layer4.0.bn2 of node add.6\n",
      "\tchecking parent layer4.0.downsample.1 of node add.6\n",
      "[find_real_parents] add.6 has 2 real parents: {'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent add.6 of node layer4.0.relu.1\n",
      "[find_real_parents] layer4.0.relu.1 has 2 real parents: {'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent layer4.0.relu.1 of node layer4.1.conv1\n",
      "[find_real_parents] layer4.1.conv1 has 2 real parents: {'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent layer4.1.conv1 of node layer4.1.bn1\n",
      "[find_real_parents] layer4.1.bn1 has 1 real parents: {'layer4.1.conv1'}\n",
      "\tchecking parent layer4.1.bn1 of node layer4.1.relu\n",
      "[find_real_parents] layer4.1.relu has 1 real parents: {'layer4.1.conv1'}\n",
      "\tchecking parent layer4.1.relu of node layer4.1.conv2\n",
      "[find_real_parents] layer4.1.conv2 has 1 real parents: {'layer4.1.conv1'}\n",
      "\tchecking parent layer4.1.conv2 of node layer4.1.bn2\n",
      "[find_real_parents] layer4.1.bn2 has 1 real parents: {'layer4.1.conv2'}\n",
      "\tchecking parent layer4.1.bn2 of node add.7\n",
      "\tchecking parent layer4.0.relu.1 of node add.7\n",
      "[find_real_parents] add.7 has 3 real parents: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent add.7 of node layer4.1.relu.1\n",
      "[find_real_parents] layer4.1.relu.1 has 3 real parents: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent layer4.1.relu.1 of node avgpool\n",
      "[find_real_parents] avgpool has 3 real parents: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent avgpool of node flatten\n",
      "[find_real_parents] flatten has 3 real parents: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\tchecking parent flatten of node fc\n",
      "[find_real_parents] fc has 3 real parents: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "\n",
      "[find_real_children] Find the real children for each node according to the whole network graph built with Torch.FX\n",
      "[find_real_children] node_name: 'fc', children: ['output']\n",
      "[find_real_children] fc has 0 real children: set()\n",
      "[find_real_children] node_name: 'flatten', children: ['fc']\n",
      "\tchecking child fc of node flatten\n",
      "[find_real_children] flatten has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'avgpool', children: ['flatten']\n",
      "\tchecking child flatten of node avgpool\n",
      "[find_real_children] avgpool has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'layer4.1.relu.1', children: ['avgpool']\n",
      "\tchecking child avgpool of node layer4.1.relu.1\n",
      "[find_real_children] layer4.1.relu.1 has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'add.7', children: ['layer4.1.relu.1']\n",
      "\tchecking child layer4.1.relu.1 of node add.7\n",
      "[find_real_children] add.7 has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'layer4.1.bn2', children: ['add.7']\n",
      "\tchecking child add.7 of node layer4.1.bn2\n",
      "[find_real_children] layer4.1.bn2 has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'layer4.1.conv2', children: ['layer4.1.bn2']\n",
      "\tchecking child layer4.1.bn2 of node layer4.1.conv2\n",
      "[find_real_children] layer4.1.conv2 has 1 real children: {'fc'}\n",
      "[find_real_children] node_name: 'layer4.1.relu', children: ['layer4.1.conv2']\n",
      "\tchecking child layer4.1.conv2 of node layer4.1.relu\n",
      "[find_real_children] layer4.1.relu has 1 real children: {'layer4.1.conv2'}\n",
      "[find_real_children] node_name: 'layer4.1.bn1', children: ['layer4.1.relu']\n",
      "\tchecking child layer4.1.relu of node layer4.1.bn1\n",
      "[find_real_children] layer4.1.bn1 has 1 real children: {'layer4.1.conv2'}\n",
      "[find_real_children] node_name: 'layer4.1.conv1', children: ['layer4.1.bn1']\n",
      "\tchecking child layer4.1.bn1 of node layer4.1.conv1\n",
      "[find_real_children] layer4.1.conv1 has 1 real children: {'layer4.1.conv2'}\n",
      "[find_real_children] node_name: 'layer4.0.relu.1', children: ['layer4.1.conv1', 'add.7']\n",
      "\tchecking child layer4.1.conv1 of node layer4.0.relu.1\n",
      "\tchecking child add.7 of node layer4.0.relu.1\n",
      "[find_real_children] layer4.0.relu.1 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'add.6', children: ['layer4.0.relu.1']\n",
      "\tchecking child layer4.0.relu.1 of node add.6\n",
      "[find_real_children] add.6 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'layer4.0.downsample.1', children: ['add.6']\n",
      "\tchecking child add.6 of node layer4.0.downsample.1\n",
      "[find_real_children] layer4.0.downsample.1 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'layer4.0.downsample.0', children: ['layer4.0.downsample.1']\n",
      "\tchecking child layer4.0.downsample.1 of node layer4.0.downsample.0\n",
      "[find_real_children] layer4.0.downsample.0 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'layer4.0.bn2', children: ['add.6']\n",
      "\tchecking child add.6 of node layer4.0.bn2\n",
      "[find_real_children] layer4.0.bn2 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'layer4.0.conv2', children: ['layer4.0.bn2']\n",
      "\tchecking child layer4.0.bn2 of node layer4.0.conv2\n",
      "[find_real_children] layer4.0.conv2 has 2 real children: {'layer4.1.conv1', 'fc'}\n",
      "[find_real_children] node_name: 'layer4.0.relu', children: ['layer4.0.conv2']\n",
      "\tchecking child layer4.0.conv2 of node layer4.0.relu\n",
      "[find_real_children] layer4.0.relu has 1 real children: {'layer4.0.conv2'}\n",
      "[find_real_children] node_name: 'layer4.0.bn1', children: ['layer4.0.relu']\n",
      "\tchecking child layer4.0.relu of node layer4.0.bn1\n",
      "[find_real_children] layer4.0.bn1 has 1 real children: {'layer4.0.conv2'}\n",
      "[find_real_children] node_name: 'layer4.0.conv1', children: ['layer4.0.bn1']\n",
      "\tchecking child layer4.0.bn1 of node layer4.0.conv1\n",
      "[find_real_children] layer4.0.conv1 has 1 real children: {'layer4.0.conv2'}\n",
      "[find_real_children] node_name: 'layer3.1.relu.1', children: ['layer4.0.conv1', 'layer4.0.downsample.0']\n",
      "\tchecking child layer4.0.conv1 of node layer3.1.relu.1\n",
      "\tchecking child layer4.0.downsample.0 of node layer3.1.relu.1\n",
      "[find_real_children] layer3.1.relu.1 has 2 real children: {'layer4.0.conv1', 'layer4.0.downsample.0'}\n",
      "[find_real_children] node_name: 'add.5', children: ['layer3.1.relu.1']\n",
      "\tchecking child layer3.1.relu.1 of node add.5\n",
      "[find_real_children] add.5 has 2 real children: {'layer4.0.conv1', 'layer4.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer3.1.bn2', children: ['add.5']\n",
      "\tchecking child add.5 of node layer3.1.bn2\n",
      "[find_real_children] layer3.1.bn2 has 2 real children: {'layer4.0.conv1', 'layer4.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer3.1.conv2', children: ['layer3.1.bn2']\n",
      "\tchecking child layer3.1.bn2 of node layer3.1.conv2\n",
      "[find_real_children] layer3.1.conv2 has 2 real children: {'layer4.0.conv1', 'layer4.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer3.1.relu', children: ['layer3.1.conv2']\n",
      "\tchecking child layer3.1.conv2 of node layer3.1.relu\n",
      "[find_real_children] layer3.1.relu has 1 real children: {'layer3.1.conv2'}\n",
      "[find_real_children] node_name: 'layer3.1.bn1', children: ['layer3.1.relu']\n",
      "\tchecking child layer3.1.relu of node layer3.1.bn1\n",
      "[find_real_children] layer3.1.bn1 has 1 real children: {'layer3.1.conv2'}\n",
      "[find_real_children] node_name: 'layer3.1.conv1', children: ['layer3.1.bn1']\n",
      "\tchecking child layer3.1.bn1 of node layer3.1.conv1\n",
      "[find_real_children] layer3.1.conv1 has 1 real children: {'layer3.1.conv2'}\n",
      "[find_real_children] node_name: 'layer3.0.relu.1', children: ['layer3.1.conv1', 'add.5']\n",
      "\tchecking child layer3.1.conv1 of node layer3.0.relu.1\n",
      "\tchecking child add.5 of node layer3.0.relu.1\n",
      "[find_real_children] layer3.0.relu.1 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'add.4', children: ['layer3.0.relu.1']\n",
      "\tchecking child layer3.0.relu.1 of node add.4\n",
      "[find_real_children] add.4 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'layer3.0.downsample.1', children: ['add.4']\n",
      "\tchecking child add.4 of node layer3.0.downsample.1\n",
      "[find_real_children] layer3.0.downsample.1 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'layer3.0.downsample.0', children: ['layer3.0.downsample.1']\n",
      "\tchecking child layer3.0.downsample.1 of node layer3.0.downsample.0\n",
      "[find_real_children] layer3.0.downsample.0 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'layer3.0.bn2', children: ['add.4']\n",
      "\tchecking child add.4 of node layer3.0.bn2\n",
      "[find_real_children] layer3.0.bn2 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'layer3.0.conv2', children: ['layer3.0.bn2']\n",
      "\tchecking child layer3.0.bn2 of node layer3.0.conv2\n",
      "[find_real_children] layer3.0.conv2 has 3 real children: {'layer4.0.conv1', 'layer4.0.downsample.0', 'layer3.1.conv1'}\n",
      "[find_real_children] node_name: 'layer3.0.relu', children: ['layer3.0.conv2']\n",
      "\tchecking child layer3.0.conv2 of node layer3.0.relu\n",
      "[find_real_children] layer3.0.relu has 1 real children: {'layer3.0.conv2'}\n",
      "[find_real_children] node_name: 'layer3.0.bn1', children: ['layer3.0.relu']\n",
      "\tchecking child layer3.0.relu of node layer3.0.bn1\n",
      "[find_real_children] layer3.0.bn1 has 1 real children: {'layer3.0.conv2'}\n",
      "[find_real_children] node_name: 'layer3.0.conv1', children: ['layer3.0.bn1']\n",
      "\tchecking child layer3.0.bn1 of node layer3.0.conv1\n",
      "[find_real_children] layer3.0.conv1 has 1 real children: {'layer3.0.conv2'}\n",
      "[find_real_children] node_name: 'layer2.1.relu.1', children: ['layer3.0.conv1', 'layer3.0.downsample.0']\n",
      "\tchecking child layer3.0.conv1 of node layer2.1.relu.1\n",
      "\tchecking child layer3.0.downsample.0 of node layer2.1.relu.1\n",
      "[find_real_children] layer2.1.relu.1 has 2 real children: {'layer3.0.downsample.0', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'add.3', children: ['layer2.1.relu.1']\n",
      "\tchecking child layer2.1.relu.1 of node add.3\n",
      "[find_real_children] add.3 has 2 real children: {'layer3.0.downsample.0', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.1.bn2', children: ['add.3']\n",
      "\tchecking child add.3 of node layer2.1.bn2\n",
      "[find_real_children] layer2.1.bn2 has 2 real children: {'layer3.0.downsample.0', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.1.conv2', children: ['layer2.1.bn2']\n",
      "\tchecking child layer2.1.bn2 of node layer2.1.conv2\n",
      "[find_real_children] layer2.1.conv2 has 2 real children: {'layer3.0.downsample.0', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.1.relu', children: ['layer2.1.conv2']\n",
      "\tchecking child layer2.1.conv2 of node layer2.1.relu\n",
      "[find_real_children] layer2.1.relu has 1 real children: {'layer2.1.conv2'}\n",
      "[find_real_children] node_name: 'layer2.1.bn1', children: ['layer2.1.relu']\n",
      "\tchecking child layer2.1.relu of node layer2.1.bn1\n",
      "[find_real_children] layer2.1.bn1 has 1 real children: {'layer2.1.conv2'}\n",
      "[find_real_children] node_name: 'layer2.1.conv1', children: ['layer2.1.bn1']\n",
      "\tchecking child layer2.1.bn1 of node layer2.1.conv1\n",
      "[find_real_children] layer2.1.conv1 has 1 real children: {'layer2.1.conv2'}\n",
      "[find_real_children] node_name: 'layer2.0.relu.1', children: ['layer2.1.conv1', 'add.3']\n",
      "\tchecking child layer2.1.conv1 of node layer2.0.relu.1\n",
      "\tchecking child add.3 of node layer2.0.relu.1\n",
      "[find_real_children] layer2.0.relu.1 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'add.2', children: ['layer2.0.relu.1']\n",
      "\tchecking child layer2.0.relu.1 of node add.2\n",
      "[find_real_children] add.2 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.0.downsample.1', children: ['add.2']\n",
      "\tchecking child add.2 of node layer2.0.downsample.1\n",
      "[find_real_children] layer2.0.downsample.1 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.0.downsample.0', children: ['layer2.0.downsample.1']\n",
      "\tchecking child layer2.0.downsample.1 of node layer2.0.downsample.0\n",
      "[find_real_children] layer2.0.downsample.0 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.0.bn2', children: ['add.2']\n",
      "\tchecking child add.2 of node layer2.0.bn2\n",
      "[find_real_children] layer2.0.bn2 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.0.conv2', children: ['layer2.0.bn2']\n",
      "\tchecking child layer2.0.bn2 of node layer2.0.conv2\n",
      "[find_real_children] layer2.0.conv2 has 3 real children: {'layer3.0.downsample.0', 'layer2.1.conv1', 'layer3.0.conv1'}\n",
      "[find_real_children] node_name: 'layer2.0.relu', children: ['layer2.0.conv2']\n",
      "\tchecking child layer2.0.conv2 of node layer2.0.relu\n",
      "[find_real_children] layer2.0.relu has 1 real children: {'layer2.0.conv2'}\n",
      "[find_real_children] node_name: 'layer2.0.bn1', children: ['layer2.0.relu']\n",
      "\tchecking child layer2.0.relu of node layer2.0.bn1\n",
      "[find_real_children] layer2.0.bn1 has 1 real children: {'layer2.0.conv2'}\n",
      "[find_real_children] node_name: 'layer2.0.conv1', children: ['layer2.0.bn1']\n",
      "\tchecking child layer2.0.bn1 of node layer2.0.conv1\n",
      "[find_real_children] layer2.0.conv1 has 1 real children: {'layer2.0.conv2'}\n",
      "[find_real_children] node_name: 'layer1.1.relu.1', children: ['layer2.0.conv1', 'layer2.0.downsample.0']\n",
      "\tchecking child layer2.0.conv1 of node layer1.1.relu.1\n",
      "\tchecking child layer2.0.downsample.0 of node layer1.1.relu.1\n",
      "[find_real_children] layer1.1.relu.1 has 2 real children: {'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'add.1', children: ['layer1.1.relu.1']\n",
      "\tchecking child layer1.1.relu.1 of node add.1\n",
      "[find_real_children] add.1 has 2 real children: {'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.1.bn2', children: ['add.1']\n",
      "\tchecking child add.1 of node layer1.1.bn2\n",
      "[find_real_children] layer1.1.bn2 has 2 real children: {'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.1.conv2', children: ['layer1.1.bn2']\n",
      "\tchecking child layer1.1.bn2 of node layer1.1.conv2\n",
      "[find_real_children] layer1.1.conv2 has 2 real children: {'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.1.relu', children: ['layer1.1.conv2']\n",
      "\tchecking child layer1.1.conv2 of node layer1.1.relu\n",
      "[find_real_children] layer1.1.relu has 1 real children: {'layer1.1.conv2'}\n",
      "[find_real_children] node_name: 'layer1.1.bn1', children: ['layer1.1.relu']\n",
      "\tchecking child layer1.1.relu of node layer1.1.bn1\n",
      "[find_real_children] layer1.1.bn1 has 1 real children: {'layer1.1.conv2'}\n",
      "[find_real_children] node_name: 'layer1.1.conv1', children: ['layer1.1.bn1']\n",
      "\tchecking child layer1.1.bn1 of node layer1.1.conv1\n",
      "[find_real_children] layer1.1.conv1 has 1 real children: {'layer1.1.conv2'}\n",
      "[find_real_children] node_name: 'layer1.0.relu.1', children: ['layer1.1.conv1', 'add.1']\n",
      "\tchecking child layer1.1.conv1 of node layer1.0.relu.1\n",
      "\tchecking child add.1 of node layer1.0.relu.1\n",
      "[find_real_children] layer1.0.relu.1 has 3 real children: {'layer2.0.conv1', 'layer1.1.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'add', children: ['layer1.0.relu.1']\n",
      "\tchecking child layer1.0.relu.1 of node add\n",
      "[find_real_children] add has 3 real children: {'layer2.0.conv1', 'layer1.1.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.0.bn2', children: ['add']\n",
      "\tchecking child add of node layer1.0.bn2\n",
      "[find_real_children] layer1.0.bn2 has 3 real children: {'layer2.0.conv1', 'layer1.1.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.0.conv2', children: ['layer1.0.bn2']\n",
      "\tchecking child layer1.0.bn2 of node layer1.0.conv2\n",
      "[find_real_children] layer1.0.conv2 has 3 real children: {'layer2.0.conv1', 'layer1.1.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'layer1.0.relu', children: ['layer1.0.conv2']\n",
      "\tchecking child layer1.0.conv2 of node layer1.0.relu\n",
      "[find_real_children] layer1.0.relu has 1 real children: {'layer1.0.conv2'}\n",
      "[find_real_children] node_name: 'layer1.0.bn1', children: ['layer1.0.relu']\n",
      "\tchecking child layer1.0.relu of node layer1.0.bn1\n",
      "[find_real_children] layer1.0.bn1 has 1 real children: {'layer1.0.conv2'}\n",
      "[find_real_children] node_name: 'layer1.0.conv1', children: ['layer1.0.bn1']\n",
      "\tchecking child layer1.0.bn1 of node layer1.0.conv1\n",
      "[find_real_children] layer1.0.conv1 has 1 real children: {'layer1.0.conv2'}\n",
      "[find_real_children] node_name: 'maxpool', children: ['layer1.0.conv1', 'add']\n",
      "\tchecking child layer1.0.conv1 of node maxpool\n",
      "\tchecking child add of node maxpool\n",
      "[find_real_children] maxpool has 4 real children: {'layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'relu', children: ['maxpool']\n",
      "\tchecking child maxpool of node relu\n",
      "[find_real_children] relu has 4 real children: {'layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'bn1', children: ['relu']\n",
      "\tchecking child relu of node bn1\n",
      "[find_real_children] bn1 has 4 real children: {'layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[find_real_children] node_name: 'conv1', children: ['bn1']\n",
      "\tchecking child bn1 of node conv1\n",
      "[find_real_children] conv1 has 4 real children: {'layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0'}\n",
      "[make_sibling_coparent_groups]\n",
      "New sibling group 0 with GCD(C) of 3: ['conv1']\n",
      "New coparent group 0: {'layer1.0.conv2', 'layer1.1.conv2', 'conv1'}\n",
      "New sibling group 1 with GCD(C) of 64: ['layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0']\n",
      "New coparent group 1: {'layer1.0.conv1'}\n",
      "New sibling group 2 with GCD(C) of 64: ['layer1.0.conv2']\n",
      "New coparent group 2: {'layer1.1.conv1'}\n",
      "New sibling group 3 with GCD(C) of 64: ['layer1.1.conv2']\n",
      "New coparent group 3: {'layer2.0.conv1'}\n",
      "New sibling group 4 with GCD(C) of 128: ['layer2.0.conv2']\n",
      "New coparent group 4: {'layer2.0.conv2', 'layer2.1.conv2', 'layer2.0.downsample.0'}\n",
      "New sibling group 5 with GCD(C) of 128: ['layer2.1.conv1', 'layer3.0.conv1', 'layer3.0.downsample.0']\n",
      "New coparent group 5: {'layer2.1.conv1'}\n",
      "New sibling group 6 with GCD(C) of 128: ['layer2.1.conv2']\n",
      "New coparent group 6: {'layer3.0.conv1'}\n",
      "New sibling group 7 with GCD(C) of 256: ['layer3.0.conv2']\n",
      "New coparent group 7: {'layer3.0.downsample.0', 'layer3.1.conv2', 'layer3.0.conv2'}\n",
      "New sibling group 8 with GCD(C) of 256: ['layer3.1.conv1', 'layer4.0.conv1', 'layer4.0.downsample.0']\n",
      "New coparent group 8: {'layer3.1.conv1'}\n",
      "New sibling group 9 with GCD(C) of 256: ['layer3.1.conv2']\n",
      "New coparent group 9: {'layer4.0.conv1'}\n",
      "New sibling group 10 with GCD(C) of 512: ['layer4.0.conv2']\n",
      "New coparent group 10: {'layer4.1.conv2', 'layer4.0.conv2', 'layer4.0.downsample.0'}\n",
      "New sibling group 11 with GCD(C) of 512: ['fc', 'layer4.1.conv1']\n",
      "New coparent group 11: {'layer4.1.conv1'}\n",
      "New sibling group 12 with GCD(C) of 512: ['layer4.1.conv2']\n",
      "New coparent group 12: {'fc'}\n",
      "[fixup_concats]\n",
      "[enforce_dimension_agreement]\n",
      "\tconv1 has no real parents, disabling permutations along C\n",
      "\tfc has no real children, disabling permutations along K\n",
      "Making a pass at propagating permutation flags\n",
      "\tnode conv1 has poisoned the sibling group of ['conv1']: {'parents': ['x'], 'children': ['bn1'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.conv.Conv2d', 'groups_param': '1', 'C_param': '3', 'K_param': '64', 'C_permutable': False, 'K_permutable': True, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': 0, 'coparent_group_id': 0, 'real_parents': [], 'real_children': ['layer1.0.conv1', 'layer1.1.conv1', 'layer2.0.conv1', 'layer2.0.downsample.0']}\n",
      "\tnode fc has poisoned the coparent group of {'fc'}: {'parents': ['flatten'], 'children': ['output'], 'fx_op': 'call_module', 'module_type': 'torch.nn.modules.linear.Linear', 'groups_param': 'None', 'C_param': '512', 'K_param': '10', 'C_permutable': True, 'K_permutable': False, 'K_passthru': False, 'is_real': True, 'C_permuted': False, 'K_permuted': False, 'sibling_group_id': 11, 'coparent_group_id': 12, 'real_parents': ['layer4.0.conv2', 'layer4.0.downsample.0', 'layer4.1.conv2'], 'real_children': []}\n",
      "Skipping permutation for sibling group 0 since it does not allow permutations along C\n",
      "Sibling group 1 can permute along C, permuting it\n",
      "Finding permutation for sibling group 1\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.0.conv1', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.1.conv1', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([1152, 64])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.conv1', with its weight shape: 'torch.Size([1152, 64])', the matrix_group shape: 'torch.Size([2304, 64])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.downsample.0', with its weight shape: 'torch.Size([128, 64])', the matrix_group shape: 'torch.Size([2432, 64])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([2432, 64])\n",
      "Found 1 gpus\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 6745.149490095577, Pruned element abs sum: 5022.19873046875, Diff ratio: 0.25543551883568605\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2432, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.4099 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.4141 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 5049.119140625.\n",
      "Permutation for sibling group 1: [1, 8, 22, 20, 7, 4, 10, 27, 16, 9, 24, 45, 42, 55, 26, 30, 58, 57, 14, 37, 3, 40, 61, 60, 52, 17, 35, 31, 59, 19, 39, 33, 12, 32, 63, 21, 5, 0, 15, 18, 25, 23, 6, 49, 47, 2, 62, 34, 54, 53, 41, 46, 43, 29, 48, 13, 11, 51, 44, 50, 36, 28, 38, 56]\n",
      "Sibling group 2 can permute along C, permuting it\n",
      "Finding permutation for sibling group 2\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.0.conv2', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([576, 64])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 1725.2730377856553, Pruned element abs sum: 1284.8878173828125, Diff ratio: 0.25525537741438664\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(576, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.1152 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.1153 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 1300.977294921875.\n",
      "Permutation for sibling group 2: [8, 6, 34, 26, 25, 4, 14, 57, 41, 9, 21, 42, 1, 43, 54, 40, 5, 17, 62, 45, 10, 47, 16, 22, 55, 18, 49, 33, 32, 0, 44, 58, 59, 35, 7, 27, 39, 23, 15, 12, 28, 24, 19, 46, 63, 52, 2, 53, 50, 20, 61, 13, 31, 30, 29, 51, 48, 3, 37, 38, 36, 11, 56, 60]\n",
      "Sibling group 3 can permute along C, permuting it\n",
      "Finding permutation for sibling group 3\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer1.1.conv2', with its weight shape: 'torch.Size([576, 64])', the matrix_group shape: 'torch.Size([576, 64])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([576, 64])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 1728.4465909914334, Pruned element abs sum: 1286.7862548828125, Diff ratio: 0.25552443356394683\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(576, 64)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.1098 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.1099 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 1299.67333984375.\n",
      "Permutation for sibling group 3: [8, 9, 42, 41, 45, 4, 37, 36, 25, 16, 29, 28, 54, 34, 1, 38, 59, 57, 47, 56, 7, 39, 20, 51, 19, 18, 22, 21, 32, 2, 55, 3, 15, 12, 61, 14, 44, 0, 5, 46, 10, 13, 35, 60, 48, 11, 40, 49, 6, 62, 58, 24, 43, 27, 26, 63, 23, 50, 30, 33, 31, 17, 52, 53]\n",
      "Sibling group 4 can permute along C, permuting it\n",
      "Finding permutation for sibling group 4\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.0.conv2', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([1152, 128])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 4918.358132590285, Pruned element abs sum: 3654.57666015625, Diff ratio: 0.25695190109477783\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(1152, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.2400 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.2402 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 3690.232177734375.\n",
      "Permutation for sibling group 4: [107, 113, 49, 71, 116, 98, 86, 21, 20, 7, 89, 42, 106, 82, 10, 119, 0, 103, 11, 53, 18, 46, 44, 117, 24, 104, 111, 105, 60, 108, 3, 1, 59, 45, 57, 30, 15, 13, 33, 35, 63, 125, 54, 4, 69, 95, 68, 5, 126, 48, 77, 76, 115, 79, 55, 50, 12, 80, 14, 66, 27, 94, 19, 88, 97, 123, 84, 73, 16, 72, 62, 9, 74, 100, 31, 40, 64, 75, 58, 25, 114, 51, 52, 122, 65, 67, 124, 39, 36, 90, 22, 56, 34, 78, 8, 83, 109, 26, 102, 91, 43, 41, 61, 87, 70, 23, 85, 2, 6, 121, 17, 29, 81, 96, 99, 118, 112, 37, 38, 28, 110, 120, 32, 127, 101, 47, 93, 92]\n",
      "Sibling group 5 can permute along C, permuting it\n",
      "Finding permutation for sibling group 5\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.1.conv1', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.conv1', with its weight shape: 'torch.Size([2304, 128])', the matrix_group shape: 'torch.Size([3456, 128])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.downsample.0', with its weight shape: 'torch.Size([256, 128])', the matrix_group shape: 'torch.Size([3712, 128])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([3712, 128])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 14132.960504426042, Pruned element abs sum: 10522.173828125, Diff ratio: 0.2554869289537918\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(3712, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.6819 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.6823 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 10580.4052734375.\n",
      "Permutation for sibling group 5: [116, 54, 47, 62, 117, 71, 100, 120, 78, 33, 86, 45, 121, 50, 5, 51, 0, 94, 31, 29, 103, 3, 20, 110, 24, 56, 91, 35, 84, 111, 122, 49, 123, 87, 85, 7, 107, 112, 96, 65, 4, 97, 79, 77, 9, 44, 61, 99, 82, 118, 93, 95, 124, 19, 108, 52, 55, 12, 40, 92, 70, 42, 83, 34, 21, 64, 90, 88, 53, 16, 119, 104, 60, 67, 57, 22, 89, 15, 6, 37, 125, 74, 72, 126, 11, 26, 23, 66, 69, 10, 59, 114, 75, 48, 28, 105, 127, 113, 76, 115, 39, 36, 102, 1, 73, 13, 8, 14, 68, 25, 43, 41, 2, 109, 101, 38, 80, 17, 18, 46, 30, 63, 27, 81, 58, 98, 106, 32]\n",
      "Sibling group 6 can permute along C, permuting it\n",
      "Finding permutation for sibling group 6\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer2.1.conv2', with its weight shape: 'torch.Size([1152, 128])', the matrix_group shape: 'torch.Size([1152, 128])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([1152, 128])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 4893.6743581017645, Pruned element abs sum: 3644.722900390625, Diff ratio: 0.25521752497556915\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(1152, 128)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.2338 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.2340 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 3676.209228515625.\n",
      "Permutation for sibling group 6: [104, 107, 25, 29, 123, 56, 47, 34, 42, 7, 72, 75, 119, 81, 45, 59, 0, 109, 24, 23, 43, 85, 2, 102, 9, 98, 22, 57, 52, 54, 51, 11, 86, 49, 77, 74, 35, 32, 111, 73, 4, 31, 65, 68, 95, 44, 94, 116, 112, 48, 91, 89, 27, 97, 10, 113, 12, 122, 84, 121, 79, 93, 61, 66, 64, 30, 39, 38, 26, 16, 62, 120, 41, 20, 110, 69, 3, 21, 76, 118, 50, 78, 55, 125, 108, 14, 126, 114, 106, 117, 36, 58, 60, 19, 8, 1, 17, 127, 18, 115, 103, 13, 33, 40, 92, 105, 28, 63, 37, 96, 87, 67, 46, 80, 82, 99, 124, 53, 88, 90, 15, 101, 100, 83, 70, 71, 5, 6]\n",
      "Sibling group 7 can permute along C, permuting it\n",
      "Finding permutation for sibling group 7\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.0.conv2', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([2304, 256])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 13876.333689860436, Pruned element abs sum: 10326.2705078125, Diff ratio: 0.2558358181197386\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2304, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.6049 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.6054 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 10398.4697265625.\n",
      "Permutation for sibling group 7: [34, 5, 72, 7, 205, 111, 233, 33, 80, 223, 134, 97, 61, 60, 191, 225, 16, 93, 232, 45, 107, 0, 74, 168, 173, 174, 68, 64, 28, 160, 159, 31, 32, 1, 85, 66, 157, 36, 35, 177, 137, 101, 251, 50, 25, 123, 24, 158, 96, 47, 29, 124, 235, 43, 12, 228, 56, 201, 58, 195, 26, 227, 213, 210, 246, 15, 79, 23, 69, 238, 237, 10, 214, 119, 183, 171, 248, 188, 76, 138, 185, 128, 150, 187, 234, 163, 14, 109, 167, 152, 252, 178, 218, 216, 155, 94, 38, 100, 217, 203, 196, 197, 219, 48, 224, 192, 139, 89, 52, 161, 83, 4, 53, 59, 117, 240, 27, 180, 22, 182, 104, 136, 46, 41, 63, 127, 71, 149, 226, 8, 146, 18, 199, 153, 221, 220, 166, 98, 164, 87, 143, 67, 189, 82, 54, 37, 11, 118, 90, 132, 106, 17, 140, 253, 176, 110, 202, 207, 92, 75, 179, 241, 190, 121, 204, 105, 125, 77, 170, 242, 181, 169, 112, 21, 115, 151, 184, 250, 239, 3, 30, 81, 126, 236, 198, 2, 209, 44, 211, 91, 222, 20, 114, 148, 186, 103, 95, 122, 229, 215, 113, 6, 108, 57, 78, 156, 255, 154, 84, 39, 86, 208, 135, 249, 141, 133, 49, 130, 175, 51, 144, 129, 131, 212, 116, 120, 145, 88, 231, 9, 73, 70, 65, 40, 244, 162, 200, 206, 230, 19, 147, 55, 172, 62, 42, 102, 245, 247, 99, 194, 243, 193, 254, 165, 13, 142]\n",
      "Sibling group 8 can permute along C, permuting it\n",
      "Finding permutation for sibling group 8\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.1.conv1', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.conv1', with its weight shape: 'torch.Size([4608, 256])', the matrix_group shape: 'torch.Size([6912, 256])'.\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.downsample.0', with its weight shape: 'torch.Size([512, 256])', the matrix_group shape: 'torch.Size([7424, 256])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([7424, 256])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 40015.55941656593, Pruned element abs sum: 29792.990234375, Diff ratio: 0.25546485745139713\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(7424, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 1.7125 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 1.7180 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 29906.880859375.\n",
      "Permutation for sibling group 8: [77, 64, 67, 65, 36, 220, 43, 208, 105, 251, 249, 157, 163, 110, 235, 119, 16, 243, 117, 37, 202, 0, 248, 217, 121, 57, 52, 224, 136, 170, 183, 60, 32, 176, 59, 162, 166, 252, 51, 245, 206, 14, 150, 55, 25, 27, 24, 230, 96, 97, 98, 159, 41, 185, 54, 200, 56, 137, 88, 126, 28, 189, 201, 93, 227, 151, 70, 225, 223, 114, 238, 149, 181, 1, 123, 118, 63, 219, 58, 9, 108, 69, 160, 177, 175, 5, 4, 10, 45, 49, 226, 239, 7, 92, 229, 26, 254, 174, 3, 120, 90, 124, 78, 48, 99, 35, 158, 53, 17, 112, 133, 129, 143, 115, 153, 255, 94, 138, 155, 154, 40, 95, 168, 190, 207, 61, 82, 89, 31, 104, 85, 240, 13, 23, 103, 161, 34, 167, 76, 140, 173, 141, 102, 101, 241, 29, 203, 242, 165, 195, 216, 122, 6, 142, 113, 73, 215, 233, 199, 198, 152, 209, 197, 232, 211, 186, 246, 72, 222, 193, 218, 171, 19, 146, 81, 125, 87, 128, 130, 107, 135, 22, 46, 178, 21, 180, 147, 100, 237, 44, 144, 20, 30, 86, 194, 210, 250, 79, 71, 196, 221, 38, 187, 39, 204, 91, 127, 205, 231, 74, 68, 179, 109, 139, 145, 80, 156, 106, 111, 62, 191, 15, 213, 236, 50, 244, 188, 132, 212, 182, 164, 12, 2, 75, 116, 234, 11, 8, 84, 131, 247, 42, 169, 33, 184, 228, 148, 18, 192, 134, 47, 83, 253, 66, 172, 214]\n",
      "Sibling group 9 can permute along C, permuting it\n",
      "Finding permutation for sibling group 9\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer3.1.conv2', with its weight shape: 'torch.Size([2304, 256])', the matrix_group shape: 'torch.Size([2304, 256])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([2304, 256])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 13866.670959058378, Pruned element abs sum: 10324.802734375, Diff ratio: 0.2554231102144714\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(2304, 256)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 0.6193 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 0.6200 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 10389.759765625.\n",
      "Permutation for sibling group 9: [141, 49, 224, 174, 155, 58, 25, 101, 72, 205, 126, 138, 84, 68, 88, 228, 16, 206, 10, 17, 23, 0, 119, 87, 52, 61, 210, 90, 26, 42, 234, 15, 21, 34, 32, 78, 167, 46, 64, 76, 133, 148, 151, 221, 29, 97, 24, 213, 65, 142, 96, 173, 139, 13, 27, 28, 56, 69, 117, 98, 36, 214, 73, 57, 170, 45, 191, 81, 168, 106, 92, 253, 75, 30, 74, 2, 8, 86, 80, 233, 190, 128, 161, 152, 144, 5, 4, 105, 250, 107, 220, 236, 91, 193, 102, 229, 100, 187, 132, 199, 197, 202, 11, 189, 230, 104, 31, 238, 114, 79, 208, 254, 20, 3, 99, 172, 154, 162, 251, 200, 146, 121, 244, 248, 153, 186, 124, 198, 118, 175, 131, 209, 33, 216, 134, 149, 215, 240, 182, 43, 165, 51, 53, 207, 55, 47, 19, 246, 185, 158, 103, 201, 50, 130, 60, 140, 231, 157, 127, 125, 9, 217, 145, 129, 41, 156, 159, 237, 178, 82, 83, 111, 22, 112, 243, 203, 35, 176, 177, 179, 108, 109, 110, 183, 48, 204, 180, 44, 227, 160, 67, 1, 188, 93, 95, 59, 85, 120, 226, 166, 18, 135, 196, 223, 218, 71, 37, 137, 136, 150, 77, 171, 163, 211, 241, 252, 225, 222, 164, 219, 14, 40, 181, 212, 70, 94, 192, 245, 169, 12, 242, 123, 194, 116, 38, 235, 54, 63, 255, 115, 7, 62, 122, 113, 232, 239, 89, 247, 249, 6, 147, 184, 39, 66, 143, 195]\n",
      "Sibling group 10 can permute along C, permuting it\n",
      "Finding permutation for sibling group 10\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.0.conv2', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([4608, 512])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 39230.40153483472, Pruned element abs sum: 29203.208984375, Diff ratio: 0.2555974998511308\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 2.7919 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 2.7983 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 29353.71875.\n",
      "Permutation for sibling group 10: [165, 389, 326, 121, 4, 478, 49, 285, 8, 196, 176, 177, 12, 380, 169, 182, 448, 451, 221, 368, 433, 31, 476, 287, 381, 383, 302, 256, 391, 173, 395, 318, 96, 32, 175, 329, 243, 114, 487, 27, 138, 405, 23, 83, 44, 72, 74, 465, 48, 474, 339, 418, 52, 350, 89, 509, 500, 407, 503, 328, 60, 409, 411, 359, 56, 40, 491, 475, 13, 172, 25, 292, 45, 47, 128, 297, 79, 73, 76, 240, 392, 69, 300, 482, 488, 84, 81, 480, 268, 179, 321, 82, 71, 202, 313, 200, 51, 279, 229, 99, 235, 86, 357, 64, 104, 508, 219, 201, 115, 108, 212, 440, 77, 193, 131, 213, 95, 217, 248, 412, 301, 17, 257, 259, 215, 227, 262, 171, 24, 127, 162, 281, 309, 422, 134, 376, 187, 186, 345, 136, 264, 363, 470, 361, 53, 467, 444, 354, 122, 203, 148, 150, 450, 388, 190, 245, 106, 336, 50, 330, 11, 160, 310, 198, 120, 140, 125, 342, 457, 59, 57, 295, 322, 26, 323, 436, 109, 384, 28, 507, 437, 420, 472, 415, 273, 143, 360, 103, 29, 191, 506, 496, 146, 332, 441, 36, 399, 192, 204, 438, 6, 477, 139, 468, 153, 178, 155, 320, 211, 206, 307, 370, 18, 116, 205, 471, 454, 166, 38, 260, 218, 220, 222, 226, 304, 483, 14, 189, 335, 145, 311, 462, 282, 35, 340, 42, 333, 144, 276, 466, 194, 195, 286, 387, 210, 244, 247, 280, 378, 43, 117, 347, 111, 469, 30, 299, 337, 305, 481, 93, 37, 349, 351, 118, 185, 355, 19, 426, 208, 356, 314, 473, 277, 272, 142, 403, 216, 353, 154, 236, 390, 445, 486, 107, 33, 401, 366, 16, 414, 288, 327, 373, 58, 168, 293, 294, 230, 135, 62, 386, 34, 132, 20, 432, 270, 427, 352, 306, 21, 97, 75, 431, 396, 39, 261, 119, 331, 344, 298, 68, 461, 228, 511, 263, 495, 325, 181, 374, 112, 249, 265, 234, 54, 88, 406, 334, 149, 151, 152, 242, 358, 449, 410, 9, 183, 312, 315, 289, 434, 1, 246, 0, 455, 377, 156, 158, 463, 225, 428, 223, 499, 442, 266, 362, 174, 87, 253, 252, 367, 425, 94, 124, 141, 424, 105, 501, 348, 100, 123, 55, 317, 5, 452, 7, 164, 130, 443, 385, 180, 232, 319, 364, 70, 296, 416, 78, 398, 484, 485, 397, 423, 237, 101, 113, 188, 10, 404, 419, 133, 61, 63, 408, 371, 92, 369, 271, 492, 161, 233, 417, 170, 400, 421, 269, 110, 393, 394, 439, 290, 137, 231, 429, 3, 15, 2, 435, 167, 163, 497, 316, 379, 199, 129, 126, 498, 147, 258, 91, 303, 493, 207, 197, 365, 430, 382, 453, 250, 65, 458, 85, 209, 308, 255, 254, 459, 375, 324, 372, 338, 413, 241, 80, 291, 346, 239, 224, 159, 446, 479, 157, 67, 456, 489, 46, 402, 214, 238, 447, 275, 90, 274, 66, 283, 278, 267, 494, 464, 22, 102, 184, 284, 460, 343, 504, 98, 41, 502, 505, 341, 490, 251, 510]\n",
      "Sibling group 11 can permute along C, permuting it\n",
      "Finding permutation for sibling group 11\n",
      "[search_for_good_permutation] not adding dense weights for node fc to the group\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.1.conv1', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([4608, 512])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 39231.55424510974, Pruned element abs sum: 29208.95703125, Diff ratio: 0.25547285614127996\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n",
      "[accelerated_search_for_good_permutation] Take 2.8198 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 2.8268 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 29360.4140625.\n",
      "Permutation for sibling group 11: [89, 312, 456, 468, 4, 209, 160, 437, 8, 421, 130, 138, 12, 156, 413, 273, 293, 226, 343, 292, 473, 177, 214, 38, 502, 379, 494, 205, 235, 316, 97, 117, 412, 32, 111, 149, 137, 172, 191, 184, 155, 100, 482, 408, 44, 219, 48, 289, 510, 125, 42, 199, 249, 152, 323, 320, 491, 154, 257, 442, 60, 369, 276, 333, 373, 64, 213, 67, 68, 175, 423, 467, 72, 212, 193, 507, 121, 76, 406, 122, 420, 268, 361, 91, 84, 389, 443, 391, 284, 231, 11, 321, 178, 113, 6, 17, 80, 359, 390, 82, 399, 435, 466, 415, 104, 385, 102, 106, 143, 65, 95, 342, 112, 262, 259, 70, 116, 355, 31, 88, 142, 120, 128, 131, 365, 241, 7, 282, 134, 194, 195, 169, 132, 352, 417, 185, 307, 159, 27, 158, 45, 217, 267, 509, 144, 286, 188, 275, 210, 35, 198, 189, 33, 481, 208, 20, 39, 14, 26, 69, 145, 349, 59, 90, 164, 400, 403, 53, 207, 253, 9, 447, 398, 129, 451, 190, 360, 453, 28, 455, 211, 378, 240, 180, 269, 458, 92, 345, 109, 173, 441, 294, 383, 465, 484, 36, 182, 183, 440, 305, 50, 201, 203, 150, 424, 47, 474, 362, 85, 148, 274, 336, 52, 107, 433, 464, 298, 475, 460, 463, 218, 202, 425, 271, 393, 319, 250, 244, 230, 228, 309, 387, 232, 485, 486, 51, 281, 221, 501, 503, 238, 19, 469, 10, 153, 73, 246, 330, 23, 114, 21, 375, 170, 225, 252, 255, 243, 167, 181, 366, 329, 506, 402, 448, 427, 445, 55, 123, 220, 43, 222, 126, 49, 146, 272, 322, 489, 446, 480, 161, 299, 280, 94, 324, 411, 279, 368, 16, 288, 428, 430, 431, 77, 135, 278, 457, 54, 296, 462, 488, 5, 192, 200, 492, 258, 325, 350, 332, 328, 71, 140, 450, 337, 251, 367, 374, 179, 261, 317, 318, 300, 301, 380, 287, 57, 483, 139, 372, 216, 265, 364, 56, 79, 295, 504, 206, 30, 196, 351, 308, 356, 264, 98, 99, 344, 151, 414, 141, 471, 479, 15, 0, 395, 339, 331, 394, 224, 444, 227, 74, 29, 263, 115, 310, 3, 419, 418, 236, 127, 270, 357, 124, 371, 334, 498, 363, 410, 18, 370, 376, 302, 381, 436, 165, 229, 105, 384, 386, 505, 438, 168, 477, 495, 392, 404, 405, 497, 358, 388, 234, 496, 314, 157, 136, 162, 239, 354, 500, 490, 103, 476, 101, 133, 346, 429, 233, 290, 335, 171, 508, 348, 197, 377, 422, 22, 248, 93, 186, 187, 260, 470, 63, 454, 24, 277, 176, 75, 303, 382, 166, 119, 58, 78, 108, 81, 347, 174, 46, 237, 341, 452, 409, 396, 439, 66, 61, 304, 306, 315, 256, 245, 297, 25, 37, 426, 326, 472, 40, 83, 96, 87, 13, 41, 223, 459, 407, 313, 254, 247, 62, 449, 266, 147, 291, 215, 118, 397, 487, 401, 34, 110, 461, 327, 353, 2, 493, 499, 204, 434, 1, 432, 86, 285, 242, 340, 338, 416, 478, 283, 311, 163, 511]\n",
      "Sibling group 12 can permute along C, permuting it\n",
      "Finding permutation for sibling group 12\n",
      "[search_for_good_permutation] have merged the weight for node: 'layer4.1.conv2', with its weight shape: 'torch.Size([4608, 512])', the matrix_group shape: 'torch.Size([4608, 512])'.\n",
      "Searching for a good permutation for this sibling group of shape torch.Size([4608, 512])\n",
      "\n",
      "[search_for_good_permutation] Original element abs sum: 39214.156928986995, Pruned element abs sum: 29195.642578125, Diff ratio: 0.25548207931652195\n",
      "[search_for_good_permutation] Original element abs sum is different from the pruned element abs sum, further permutation search will help, continue with the permutation search!\n",
      "[search_for_good_permutation] search options: {'strategy': 'exhaustive', 'stripe_group_size': 8, 'escape_attempts': 100}\n",
      "\n",
      "[accelerated_search_for_good_permutation] input matrix shape: '(4608, 512)'.\n",
      "[accelerated_search_for_good_permutation] the permutation strategy is: 'exhaustive search'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/apex/contrib/sparsity/sparse_masklib.py:42: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  mask = torch.cuda.IntTensor(matrix.shape).fill_(1).view(-1,m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[accelerated_search_for_good_permutation] Take 2.8250 seconds to search the permutation sequence.\n",
      "[search_for_good_permutation] Take 2.8318 seconds to finish accelerated_search_for_good_permutation function and with final magnitude 29342.548828125.\n",
      "Permutation for sibling group 12: [59, 130, 312, 38, 4, 275, 326, 511, 8, 142, 170, 454, 12, 105, 319, 90, 205, 300, 104, 284, 20, 349, 320, 198, 24, 224, 147, 145, 178, 301, 240, 161, 428, 210, 47, 385, 252, 88, 444, 487, 291, 61, 318, 383, 190, 256, 504, 106, 48, 427, 49, 437, 52, 403, 35, 507, 328, 78, 330, 331, 60, 134, 11, 414, 453, 64, 389, 321, 68, 71, 69, 276, 72, 486, 119, 112, 334, 100, 333, 509, 431, 265, 442, 117, 44, 348, 314, 128, 66, 323, 239, 322, 203, 168, 163, 13, 41, 257, 466, 136, 42, 196, 40, 98, 471, 367, 227, 407, 108, 350, 338, 441, 484, 46, 343, 340, 116, 299, 264, 366, 295, 120, 292, 353, 267, 255, 364, 365, 74, 186, 129, 75, 132, 496, 109, 285, 317, 200, 97, 73, 191, 409, 499, 341, 110, 344, 131, 144, 148, 149, 324, 473, 164, 358, 310, 425, 332, 296, 355, 153, 27, 93, 115, 160, 125, 288, 375, 423, 379, 297, 261, 269, 99, 172, 494, 197, 32, 391, 28, 470, 180, 368, 469, 183, 278, 283, 282, 410, 18, 143, 249, 380, 468, 76, 65, 29, 174, 214, 402, 325, 30, 202, 305, 413, 254, 467, 228, 94, 188, 490, 102, 53, 263, 212, 231, 209, 416, 241, 472, 429, 96, 412, 376, 311, 229, 242, 167, 419, 34, 33, 485, 230, 17, 126, 234, 157, 79, 77, 329, 150, 152, 81, 83, 462, 481, 478, 151, 286, 421, 451, 248, 503, 70, 62, 354, 335, 36, 55, 5, 54, 461, 362, 260, 137, 247, 337, 244, 140, 133, 226, 193, 26, 493, 272, 405, 406, 216, 218, 477, 346, 482, 266, 483, 480, 207, 497, 86, 156, 393, 238, 3, 445, 9, 245, 121, 408, 258, 381, 277, 370, 294, 58, 31, 418, 439, 309, 307, 63, 404, 396, 273, 293, 342, 135, 448, 449, 122, 316, 50, 438, 433, 434, 302, 169, 268, 270, 67, 374, 56, 162, 177, 39, 232, 95, 89, 213, 15, 1, 155, 14, 447, 215, 400, 446, 22, 476, 223, 382, 208, 16, 465, 0, 390, 280, 154, 500, 166, 138, 7, 114, 206, 411, 361, 455, 363, 19, 432, 21, 233, 235, 165, 124, 246, 199, 415, 372, 397, 237, 436, 452, 491, 101, 394, 510, 384, 82, 463, 443, 388, 290, 158, 10, 395, 262, 194, 85, 505, 57, 303, 378, 184, 458, 187, 43, 146, 221, 171, 189, 220, 222, 211, 401, 506, 371, 298, 440, 327, 392, 84, 87, 251, 422, 377, 250, 386, 204, 225, 287, 127, 45, 387, 430, 352, 179, 259, 192, 51, 460, 201, 304, 435, 315, 464, 243, 398, 159, 289, 359, 236, 176, 111, 450, 308, 347, 23, 508, 351, 123, 456, 457, 92, 25, 479, 107, 459, 357, 420, 356, 369, 495, 91, 80, 118, 417, 474, 475, 498, 103, 217, 274, 313, 426, 175, 6, 139, 360, 113, 253, 488, 281, 2, 489, 345, 173, 492, 373, 37, 195, 219, 271, 279, 306, 501, 502, 141, 399, 336, 339, 181, 424, 182, 185]\n",
      "\n",
      "[permute_model] Take 13.3332 seconds to finish search_for_good_permutation function.\n",
      "Attempting to permute sibling group 1\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.0.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.1.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.downsample.0' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.conv2' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.0.conv2 : ['layer1.0.bn2']\n",
      "\tPermuting layer1.0.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.0.bn2 : ['add']\n",
      "\tPermuting children of non-module add along K\n",
      "Applying a permutation in K to children of add : ['layer1.0.relu.1']\n",
      "Applying a permutation in K to children of layer1.0.relu.1 : ['layer1.1.conv1', 'add.1']\n",
      "\tFound a real child layer1.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.1 along K\n",
      "Applying a permutation in K to children of add.1 : ['layer1.1.relu.1']\n",
      "Applying a permutation in K to children of layer1.1.relu.1 : ['layer2.0.conv1', 'layer2.0.downsample.0']\n",
      "\tFound a real child layer2.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer2.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.conv2' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.1.conv2 : ['layer1.1.bn2']\n",
      "\tPermuting layer1.1.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn2' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.1.bn2 : ['add.1']\n",
      "\tPermuting children of non-module add.1 along K\n",
      "Applying a permutation in K to children of add.1 : ['layer1.1.relu.1']\n",
      "Applying a permutation in K to children of layer1.1.relu.1 : ['layer2.0.conv1', 'layer2.0.downsample.0']\n",
      "\tFound a real child layer2.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer2.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'conv1' with shape: 'torch.Size([64, 3, 7, 7])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of conv1 : ['bn1']\n",
      "\tPermuting bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of bn1 : ['relu']\n",
      "Applying a permutation in K to children of relu : ['maxpool']\n",
      "Applying a permutation in K to children of maxpool : ['layer1.0.conv1', 'add']\n",
      "\tFound a real child layer1.0.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add along K\n",
      "Applying a permutation in K to children of add : ['layer1.0.relu.1']\n",
      "Applying a permutation in K to children of layer1.0.relu.1 : ['layer1.1.conv1', 'add.1']\n",
      "\tFound a real child layer1.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.1 along K\n",
      "Applying a permutation in K to children of add.1 : ['layer1.1.relu.1']\n",
      "Applying a permutation in K to children of layer1.1.relu.1 : ['layer2.0.conv1', 'layer2.0.downsample.0']\n",
      "\tFound a real child layer2.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer2.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'bn1' in K dim\n",
      "Attempting to permute sibling group 2\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.0.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.conv1' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.0.conv1 : ['layer1.0.bn1']\n",
      "\tPermuting layer1.0.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.0.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.0.bn1 : ['layer1.0.relu']\n",
      "Applying a permutation in K to children of layer1.0.relu : ['layer1.0.conv2']\n",
      "\tFound a real child layer1.0.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.0.bn1' in K dim\n",
      "Attempting to permute sibling group 3\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer1.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer1.1.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.conv1' with shape: 'torch.Size([64, 64, 3, 3])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.1.conv1 : ['layer1.1.bn1']\n",
      "\tPermuting layer1.1.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer1.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer1.1.bn1' with shape: 'torch.Size([64])', can match the size of permutation sequence with len: '64', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer1.1.bn1 : ['layer1.1.relu']\n",
      "Applying a permutation in K to children of layer1.1.relu : ['layer1.1.conv2']\n",
      "\tFound a real child layer1.1.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer1.1.bn1' in K dim\n",
      "Attempting to permute sibling group 4\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.0.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.conv1' with shape: 'torch.Size([128, 64, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.conv1 : ['layer2.0.bn1']\n",
      "\tPermuting layer2.0.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.bn1 : ['layer2.0.relu']\n",
      "Applying a permutation in K to children of layer2.0.relu : ['layer2.0.conv2']\n",
      "\tFound a real child layer2.0.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn1' in K dim\n",
      "Attempting to permute sibling group 5\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.1.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.downsample.0' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.conv2' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.conv2 : ['layer2.0.bn2']\n",
      "\tPermuting layer2.0.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.bn2 : ['add.2']\n",
      "\tPermuting children of non-module add.2 along K\n",
      "Applying a permutation in K to children of add.2 : ['layer2.0.relu.1']\n",
      "Applying a permutation in K to children of layer2.0.relu.1 : ['layer2.1.conv1', 'add.3']\n",
      "\tFound a real child layer2.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.3 along K\n",
      "Applying a permutation in K to children of add.3 : ['layer2.1.relu.1']\n",
      "Applying a permutation in K to children of layer2.1.relu.1 : ['layer3.0.conv1', 'layer3.0.downsample.0']\n",
      "\tFound a real child layer3.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer3.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.conv2' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.1.conv2 : ['layer2.1.bn2']\n",
      "\tPermuting layer2.1.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn2' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.1.bn2 : ['add.3']\n",
      "\tPermuting children of non-module add.3 along K\n",
      "Applying a permutation in K to children of add.3 : ['layer2.1.relu.1']\n",
      "Applying a permutation in K to children of layer2.1.relu.1 : ['layer3.0.conv1', 'layer3.0.downsample.0']\n",
      "\tFound a real child layer3.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer3.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.0' with shape: 'torch.Size([128, 64, 1, 1])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.downsample.0 : ['layer2.0.downsample.1']\n",
      "\tPermuting layer2.0.downsample.1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.0.downsample.1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.0.downsample.1 : ['add.2']\n",
      "\tPermuting children of non-module add.2 along K\n",
      "Applying a permutation in K to children of add.2 : ['layer2.0.relu.1']\n",
      "Applying a permutation in K to children of layer2.0.relu.1 : ['layer2.1.conv1', 'add.3']\n",
      "\tFound a real child layer2.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.3 along K\n",
      "Applying a permutation in K to children of add.3 : ['layer2.1.relu.1']\n",
      "Applying a permutation in K to children of layer2.1.relu.1 : ['layer3.0.conv1', 'layer3.0.downsample.0']\n",
      "\tFound a real child layer3.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer3.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.0.downsample.1' in K dim\n",
      "Attempting to permute sibling group 6\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer2.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer2.1.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.conv1' with shape: 'torch.Size([128, 128, 3, 3])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.1.conv1 : ['layer2.1.bn1']\n",
      "\tPermuting layer2.1.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer2.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer2.1.bn1' with shape: 'torch.Size([128])', can match the size of permutation sequence with len: '128', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer2.1.bn1 : ['layer2.1.relu']\n",
      "Applying a permutation in K to children of layer2.1.relu : ['layer2.1.conv2']\n",
      "\tFound a real child layer2.1.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer2.1.bn1' in K dim\n",
      "Attempting to permute sibling group 7\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.0.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.conv1' with shape: 'torch.Size([256, 128, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.conv1 : ['layer3.0.bn1']\n",
      "\tPermuting layer3.0.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.bn1 : ['layer3.0.relu']\n",
      "Applying a permutation in K to children of layer3.0.relu : ['layer3.0.conv2']\n",
      "\tFound a real child layer3.0.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn1' in K dim\n",
      "Attempting to permute sibling group 8\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.1.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.downsample.0' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.downsample.0' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.0' with shape: 'torch.Size([256, 128, 1, 1])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.downsample.0 : ['layer3.0.downsample.1']\n",
      "\tPermuting layer3.0.downsample.1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.downsample.1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.downsample.1 : ['add.4']\n",
      "\tPermuting children of non-module add.4 along K\n",
      "Applying a permutation in K to children of add.4 : ['layer3.0.relu.1']\n",
      "Applying a permutation in K to children of layer3.0.relu.1 : ['layer3.1.conv1', 'add.5']\n",
      "\tFound a real child layer3.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.5 along K\n",
      "Applying a permutation in K to children of add.5 : ['layer3.1.relu.1']\n",
      "Applying a permutation in K to children of layer3.1.relu.1 : ['layer4.0.conv1', 'layer4.0.downsample.0']\n",
      "\tFound a real child layer4.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer4.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.conv2' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.1.conv2 : ['layer3.1.bn2']\n",
      "\tPermuting layer3.1.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.1.bn2 : ['add.5']\n",
      "\tPermuting children of non-module add.5 along K\n",
      "Applying a permutation in K to children of add.5 : ['layer3.1.relu.1']\n",
      "Applying a permutation in K to children of layer3.1.relu.1 : ['layer4.0.conv1', 'layer4.0.downsample.0']\n",
      "\tFound a real child layer4.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer4.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.conv2' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.conv2 : ['layer3.0.bn2']\n",
      "\tPermuting layer3.0.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.0.bn2' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.0.bn2 : ['add.4']\n",
      "\tPermuting children of non-module add.4 along K\n",
      "Applying a permutation in K to children of add.4 : ['layer3.0.relu.1']\n",
      "Applying a permutation in K to children of layer3.0.relu.1 : ['layer3.1.conv1', 'add.5']\n",
      "\tFound a real child layer3.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.5 along K\n",
      "Applying a permutation in K to children of add.5 : ['layer3.1.relu.1']\n",
      "Applying a permutation in K to children of layer3.1.relu.1 : ['layer4.0.conv1', 'layer4.0.downsample.0']\n",
      "\tFound a real child layer4.0.conv1, not permuting it or its children along K\n",
      "\tFound a real child layer4.0.downsample.0, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.0.bn2' in K dim\n",
      "Attempting to permute sibling group 9\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer3.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer3.1.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.conv1' with shape: 'torch.Size([256, 256, 3, 3])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.1.conv1 : ['layer3.1.bn1']\n",
      "\tPermuting layer3.1.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer3.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer3.1.bn1' with shape: 'torch.Size([256])', can match the size of permutation sequence with len: '256', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer3.1.bn1 : ['layer3.1.relu']\n",
      "Applying a permutation in K to children of layer3.1.relu : ['layer3.1.conv2']\n",
      "\tFound a real child layer3.1.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer3.1.bn1' in K dim\n",
      "Attempting to permute sibling group 10\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.0.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.0.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.conv1' with shape: 'torch.Size([512, 256, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.conv1 : ['layer4.0.bn1']\n",
      "\tPermuting layer4.0.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.bn1 : ['layer4.0.relu']\n",
      "Applying a permutation in K to children of layer4.0.relu : ['layer4.0.conv2']\n",
      "\tFound a real child layer4.0.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn1' in K dim\n",
      "Attempting to permute sibling group 11\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'fc' in C dim\n",
      "[apply_permutation_in_C_dim] cannot find the node: 'fc' 'weight' in cls.__sparse_parameters, but can find in cls.__all_parameters.\n",
      "[apply_permutation_in_C_dim] cannot find the node: 'fc' in cls.__sparse_parameters, after trying with cls.__all_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.1.conv1' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.1.conv1' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.conv2' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.1.conv2 : ['layer4.1.bn2']\n",
      "\tPermuting layer4.1.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.1.bn2 : ['add.7']\n",
      "\tPermuting children of non-module add.7 along K\n",
      "Applying a permutation in K to children of add.7 : ['layer4.1.relu.1']\n",
      "Applying a permutation in K to children of layer4.1.relu.1 : ['avgpool']\n",
      "Applying a permutation in K to children of avgpool : ['flatten']\n",
      "\tPermuting children of non-module flatten along K\n",
      "Applying a permutation in K to children of flatten : ['fc']\n",
      "\tFound a real child fc, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.conv2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.conv2' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.conv2 : ['layer4.0.bn2']\n",
      "\tPermuting layer4.0.bn2 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.bn2' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.bn2' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.bn2 : ['add.6']\n",
      "\tPermuting children of non-module add.6 along K\n",
      "Applying a permutation in K to children of add.6 : ['layer4.0.relu.1']\n",
      "Applying a permutation in K to children of layer4.0.relu.1 : ['layer4.1.conv1', 'add.7']\n",
      "\tFound a real child layer4.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.7 along K\n",
      "Applying a permutation in K to children of add.7 : ['layer4.1.relu.1']\n",
      "Applying a permutation in K to children of layer4.1.relu.1 : ['avgpool']\n",
      "Applying a permutation in K to children of avgpool : ['flatten']\n",
      "\tPermuting children of non-module flatten along K\n",
      "Applying a permutation in K to children of flatten : ['fc']\n",
      "\tFound a real child fc, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.0' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.0' with shape: 'torch.Size([512, 256, 1, 1])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.downsample.0 : ['layer4.0.downsample.1']\n",
      "\tPermuting layer4.0.downsample.1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.0.downsample.1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.0.downsample.1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.0.downsample.1 : ['add.6']\n",
      "\tPermuting children of non-module add.6 along K\n",
      "Applying a permutation in K to children of add.6 : ['layer4.0.relu.1']\n",
      "Applying a permutation in K to children of layer4.0.relu.1 : ['layer4.1.conv1', 'add.7']\n",
      "\tFound a real child layer4.1.conv1, not permuting it or its children along K\n",
      "\tPermuting children of non-module add.7 along K\n",
      "Applying a permutation in K to children of add.7 : ['layer4.1.relu.1']\n",
      "Applying a permutation in K to children of layer4.1.relu.1 : ['avgpool']\n",
      "Applying a permutation in K to children of avgpool : ['flatten']\n",
      "\tPermuting children of non-module flatten along K\n",
      "Applying a permutation in K to children of flatten : ['fc']\n",
      "\tFound a real child fc, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.conv2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.bn2' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.0' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.0.downsample.1' in K dim\n",
      "Attempting to permute sibling group 12\n",
      "[apply_permutation_in_C_dim] Permutation for node: 'layer4.1.conv2' in C dim\n",
      "[apply_permutation_in_C_dim] find the node: 'layer4.1.conv2' 'weight' in cls.__sparse_parameters, succeed to apply permutation in C dim.\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.conv1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.conv1' with shape: 'torch.Size([512, 512, 3, 3])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.1.conv1 : ['layer4.1.bn1']\n",
      "\tPermuting layer4.1.bn1 along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn1' in K dim\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'weight' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'bias' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'running_mean' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] find the node: 'layer4.1.bn1' with 'running_var' in cls.__all_parameters, may succeed to apply permutation in K dim.\n",
      "[apply_permutation_in_K_dim] the node: 'layer4.1.bn1' with shape: 'torch.Size([512])', can match the size of permutation sequence with len: '512', succeed to apply permutation in K dim.\n",
      "Applying a permutation in K to children of layer4.1.bn1 : ['layer4.1.relu']\n",
      "Applying a permutation in K to children of layer4.1.relu : ['layer4.1.conv2']\n",
      "\tFound a real child layer4.1.conv2, not permuting it or its children along K\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.conv1' in K dim\n",
      "[apply_permutation_in_K_dim] Permutation for node: 'layer4.1.bn1' in K dim\n",
      "[check_graph_for_unpermuted_nodes] found nodes that missed permutations along 0 dimensions.\n",
      "\n",
      "[compute_sparse_masks] permuted the model.\n",
      "[compute_sparse_masks] Take 13.3704 seconds to find and apply permutations.\n",
      "[ASP] Enabled 50.00% sparsity for layer1.0.conv1::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32 with magnitude tensor(1302.0945, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer1.0.conv2::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32 with magnitude tensor(1300.9778, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer1.1.conv1::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32 with magnitude tensor(1300.1931, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer1.1.conv2::weight of size=torch.Size([64, 64, 3, 3]) and type=torch.float32 with magnitude tensor(1299.6726, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.conv1::weight of size=torch.Size([128, 64, 3, 3]) and type=torch.float32 with magnitude tensor(1834.9028, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.conv2::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32 with magnitude tensor(3690.2324, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer2.0.downsample.0::weight of size=torch.Size([128, 64, 1, 1]) and type=torch.float32 with magnitude tensor(611.9271, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer2.1.conv1::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32 with magnitude tensor(3672.5005, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer2.1.conv2::weight of size=torch.Size([128, 128, 3, 3]) and type=torch.float32 with magnitude tensor(3676.2114, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.conv1::weight of size=torch.Size([256, 128, 3, 3]) and type=torch.float32 with magnitude tensor(5169.3496, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.conv2::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32 with magnitude tensor(10398.4775, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer3.0.downsample.0::weight of size=torch.Size([256, 128, 1, 1]) and type=torch.float32 with magnitude tensor(1738.5148, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer3.1.conv1::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32 with magnitude tensor(10377.8545, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer3.1.conv2::weight of size=torch.Size([256, 256, 3, 3]) and type=torch.float32 with magnitude tensor(10389.7686, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.conv1::weight of size=torch.Size([512, 256, 3, 3]) and type=torch.float32 with magnitude tensor(14623.7910, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.conv2::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32 with magnitude tensor(29353.6992, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer4.0.downsample.0::weight of size=torch.Size([512, 256, 1, 1]) and type=torch.float32 with magnitude tensor(4905.2412, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer4.1.conv1::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32 with magnitude tensor(29360.4688, device='cuda:0')\n",
      "[ASP] Enabled 50.00% sparsity for layer4.1.conv2::weight of size=torch.Size([512, 512, 3, 3]) and type=torch.float32 with magnitude tensor(29342.7988, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 2.5715417861938477 \n",
      "Current LR is [0.009972609476841367]\n",
      "1061/3925 correct, 27.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 1.8728474378585815 \n",
      "Current LR is [0.009890738003669028]\n",
      "1676/3925 correct, 42.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 1.2360942363739014 \n",
      "Current LR is [0.009755282581475769]\n",
      "2358/3925 correct, 60.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 1.4558587074279785 \n",
      "Current LR is [0.009567727288213004]\n",
      "2095/3925 correct, 53.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 1.1891218423843384 \n",
      "Current LR is [0.009330127018922194]\n",
      "2476/3925 correct, 63.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 2.1081368923187256 \n",
      "Current LR is [0.009045084971874737]\n",
      "1702/3925 correct, 43.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 1.5070277452468872 \n",
      "Current LR is [0.00871572412738697]\n",
      "2339/3925 correct, 59.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 1.1745232343673706 \n",
      "Current LR is [0.008345653031794291]\n",
      "2479/3925 correct, 63.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 1.982565999031067 \n",
      "Current LR is [0.007938926261462365]\n",
      "1670/3925 correct, 42.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 0.9643592238426208 \n",
      "Current LR is [0.007499999999999999]\n",
      "2685/3925 correct, 68.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 0.9910804033279419 \n",
      "Current LR is [0.007033683215379001]\n",
      "2712/3925 correct, 69.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 0.7725822925567627 \n",
      "Current LR is [0.0065450849718747366]\n",
      "2967/3925 correct, 75.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 0.7226162552833557 \n",
      "Current LR is [0.006039558454088796]\n",
      "3038/3925 correct, 77.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 52.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 0.8984676599502563 \n",
      "Current LR is [0.0055226423163382676]\n",
      "2812/3925 correct, 71.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 0.7187636494636536 \n",
      "Current LR is [0.005000000000000001]\n",
      "3032/3925 correct, 77.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 0.675044596195221 \n",
      "Current LR is [0.0044773576836617335]\n",
      "3060/3925 correct, 77.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 0.6567634344100952 \n",
      "Current LR is [0.003960441545911203]\n",
      "3113/3925 correct, 79.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 0.6024516820907593 \n",
      "Current LR is [0.003454915028125263]\n",
      "3174/3925 correct, 80.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 52.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 0.6780432462692261 \n",
      "Current LR is [0.0029663167846209998]\n",
      "3110/3925 correct, 79.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 0.5982910990715027 \n",
      "Current LR is [0.002500000000000001]\n",
      "3195/3925 correct, 81.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 0.5808752775192261 \n",
      "Current LR is [0.0020610737385376348]\n",
      "3180/3925 correct, 81.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 0.5678159594535828 \n",
      "Current LR is [0.0016543469682057104]\n",
      "3229/3925 correct, 82.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 0.6271165609359741 \n",
      "Current LR is [0.0012842758726130299]\n",
      "3182/3925 correct, 81.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 0.5499690175056458 \n",
      "Current LR is [0.0009549150281252634]\n",
      "3258/3925 correct, 83.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 0.5233604907989502 \n",
      "Current LR is [0.0006698729810778065]\n",
      "3287/3925 correct, 83.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 54.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 0.5240201354026794 \n",
      "Current LR is [0.00043227271178699516]\n",
      "3261/3925 correct, 83.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 0.5107554793357849 \n",
      "Current LR is [0.00024471741852423234]\n",
      "3301/3925 correct, 84.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 0.5127426385879517 \n",
      "Current LR is [0.00010926199633097157]\n",
      "3306/3925 correct, 84.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 0.506304919719696 \n",
      "Current LR is [2.7390523158632995e-05]\n",
      "3304/3925 correct, 84.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 148/148 [00:02<00:00, 53.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 0.5037730932235718 \n",
      "Current LR is [0.0]\n",
      "3311/3925 correct, 84.36%\n"
     ]
    }
   ],
   "source": [
    "from apex.contrib.sparsity import ASP\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "epochs = 30\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "ASP.prune_trained_model(model, optimizer)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "loss_plot = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (images, target) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        targets = target.to(device)\n",
    "\n",
    "        outs = model(images)\n",
    "        loss = lossfn(outs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = len(val_loader.dataset)\n",
    "    for i, (images, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            targets = target.to(device)\n",
    "            outs = model(images)\n",
    "\n",
    "            loss = lossfn(outs, targets)\n",
    "            losses.append(loss)\n",
    "            for x in range(outs.shape[0]):\n",
    "                preds = F.softmax(outs, dim=1)\n",
    "                cls = preds[x].argmax()\n",
    "                lbl = targets[x]\n",
    "                if cls == lbl:\n",
    "                    correct += 1\n",
    "\n",
    "    epoch_loss = torch.Tensor(losses).mean().item()\n",
    "    print(\"Epoch {}: {} \".format(epoch, epoch_loss))\n",
    "    print(\"Current LR is {}\".format(scheduler.get_last_lr()))\n",
    "    print(\"{}/{} correct, {:.2f}%\".format(correct, total, 100*correct/total))\n",
    "    loss_plot.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae7454a0-0e67-4d55-a8ee-c98849627521",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"sparse_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5eff40f-b24d-4113-8d33-3c5af37b195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Tensorrt has problems importing the model if it's exported by dynamo.\n",
    "torch_input = torch.randn(1, 3, DIM, DIM).to(device)\n",
    "onnx_program = torch.onnx.export(\n",
    "    model,\n",
    "    (torch_input,),\n",
    "    \"sparse_resnet.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamo=False,\n",
    "    external_data=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b13c5a-2561-4b79-b9c9-a95948cfe375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726439fa38c6451abab4896ecd7f791e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='index', max=3924), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0, len(val_loader.dataset) - 1, 1))\n",
    "def draw_preds(index=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = val_loader.dataset[index][0]\n",
    "        pred = model(image.float().unsqueeze(0).to(device))\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        clsid = pred.argmax()\n",
    "        plt.imshow(image.float().cpu().squeeze().permute(1, 2, 0), cmap='gray')\n",
    "        print(int(clsid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb8c03-10c5-4c37-a093-e84f040d1450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
