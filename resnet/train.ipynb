{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f15744-6456-4184-91b4-79fcf9f1da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision tqdm matplotlib onnx onnxscript\n",
    "# sudo docker run -it --rm --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v$(pwd):/run/host -p 8888:8888 nvcr.io/nvidia/pytorch:24.12-py3\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('high')\n",
    "import torch.utils.data as tud\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as tvt\n",
    "import torchvision.transforms.v2 as tv2\n",
    "import torchvision.transforms.functional as tvf\n",
    "import torchvision.datasets as tds\n",
    "import torchvision.utils as tu\n",
    "import torchvision\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "cpu_num = os.cpu_count() // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449b1eaf-c29c-4b56-9c21-266fa3e40c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = './datasets'\n",
    "\n",
    "DIM=160\n",
    "\n",
    "train_tfs = tvt.Compose([\n",
    "    tv2.RandomCrop(DIM, 4),\n",
    "    tvt.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.1\n",
    "    ),\n",
    "    tv2.RandomHorizontalFlip(0.5),\n",
    "    tv2.RandomVerticalFlip(0.25),\n",
    "    tv2.ToImage(),\n",
    "    tv2.ToDtype(torch.float32, scale=True)\n",
    "])\n",
    "\n",
    "val_tfs = tvt.Compose([\n",
    "    tv2.CenterCrop(DIM),\n",
    "    tv2.ToImage(),\n",
    "    tv2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "train = tds.imagenette.Imagenette(\n",
    "    dataset_root,\n",
    "    \"train\",\n",
    "    \"160px\",\n",
    "    download=True,\n",
    "    transform=train_tfs\n",
    ")\n",
    "\n",
    "val = tds.imagenette.Imagenette(\n",
    "    dataset_root,\n",
    "    \"val\",\n",
    "    \"160px\",\n",
    "    download=False,\n",
    "    transform=val_tfs\n",
    ")\n",
    "\n",
    "batchsize = 64\n",
    "\n",
    "train_loader = tud.DataLoader(train, batch_size=batchsize, num_workers=cpu_num, shuffle=True)\n",
    "val_loader = tud.DataLoader(val, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6710146-c743-41fc-bff6-d61e3684b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=None)\n",
    "# Replace the head b/c imagenette has only 10 classes.\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "model = model.to(device).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b5140-3593-4f69-b592-2bb0af0d67b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from apex.contrib.sparsity import ASP\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "epochs = 30\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "ASP.prune_trained_model(model, optimizer)\n",
    "\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "loss_plot = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for i, (images, target) in enumerate(tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        targets = target.to(device)\n",
    "\n",
    "        outs = model(images)\n",
    "        loss = lossfn(outs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    losses = []\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = len(val)\n",
    "    for i, (images, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            images = images.to(device)\n",
    "            targets = target.to(device)\n",
    "            outs = model(images)\n",
    "\n",
    "            loss = lossfn(outs, targets)\n",
    "            losses.append(loss)\n",
    "            for x in range(outs.shape[0]):\n",
    "                preds = F.softmax(outs, dim=1)\n",
    "                cls = preds[x].argmax()\n",
    "                lbl = targets[x]\n",
    "                if cls == lbl:\n",
    "                    correct += 1\n",
    "\n",
    "    epoch_loss = torch.Tensor(losses).mean().item()\n",
    "    print(\"Epoch {}: {} \".format(epoch, epoch_loss))\n",
    "    print(\"Current LR is {}\".format(scheduler.get_last_lr()))\n",
    "    print(\"{}/{} correct, {:.2f}%\".format(correct, total, 100*correct/total))\n",
    "    loss_plot.append(epoch_loss)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7454a0-0e67-4d55-a8ee-c98849627521",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"sparse_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eff40f-b24d-4113-8d33-3c5af37b195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_input = torch.randn(1, 3, DIM, DIM).to(device)\n",
    "onnx_program = torch.onnx.dynamo_export(model, torch_input)\n",
    "onnx_program.save(\"sparse_resnet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b13c5a-2561-4b79-b9c9-a95948cfe375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "@interact(index=(0, len(val) - 1, 1))\n",
    "def draw_preds(index=0):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = val[index][0]\n",
    "        pred = model(image.float().unsqueeze(0).to(device))\n",
    "        pred = F.softmax(pred, dim=1)\n",
    "        clsid = pred.argmax()\n",
    "        plt.imshow(image.float().cpu().squeeze().permute(1, 2, 0), cmap='gray')\n",
    "        print(int(clsid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf35dd-687e-4a43-a842-cab5875ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "\n",
    "trt_batch_size = 1\n",
    "logger = trt.Logger(trt.Logger.INFO)\n",
    "builder = trt.Builder(logger)\n",
    "network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))\n",
    "parser = trt.OnnxParser(network, logger)\n",
    "\n",
    "with open(\"sparse_resnet.onnx\", \"rb\") as f:\n",
    "    print(\"Load ONNX.\")\n",
    "    parser.parse(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56cf2b-f1fb-425e-ab29-32e1018eff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = builder.create_optimization_profile()\n",
    "profile.set_shape(\n",
    "    'input',\n",
    "    (trt_batch_size, 3, DIM, DIM),\n",
    "    (trt_batch_size, 3, DIM, DIM),\n",
    "    (trt_batch_size, 3, DIM, DIM)\n",
    ")\n",
    "\n",
    "config = builder.create_builder_config()\n",
    "config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, 1 << 30)\n",
    "config.add_optimization_profile(profile)\n",
    "config.set_calibration_profile(profile)\n",
    "config.set_flag(trt.BuilderFlag.SPARSE_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9ece3-9524-4eeb-b10c-1adf8161d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetCalibrator(trt.IInt8Calibrator):\n",
    "    def __init__(self,\n",
    "            input, dataset,\n",
    "            algorithm=trt.CalibrationAlgoType.ENTROPY_CALIBRATION_2):\n",
    "        super(DatasetCalibrator, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.algorithm = algorithm\n",
    "        self.buffer = torch.zeros_like(input).contiguous().cuda() # Must move tensor to GPU here!\n",
    "        self.count = 0\n",
    "\n",
    "    def get_batch(self, *args, **kwargs):\n",
    "        if self.count < len(self.dataset):\n",
    "            for buffer_idx in range(self.get_batch_size()):\n",
    "                dataset_idx = self.count % len(self.dataset) # roll around if not multiple of dataset\n",
    "                image, _ = self.dataset[dataset_idx]\n",
    "                image = image.to(self.buffer.device)\n",
    "                self.buffer[buffer_idx].copy_(image)\n",
    "\n",
    "                self.count += 1\n",
    "            return [int(self.buffer.data_ptr())]\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    def get_algorithm(self):\n",
    "        return self.algorithm\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return int(self.buffer.shape[0])\n",
    "\n",
    "    def read_calibration_cache(self, *args, **kwargs):\n",
    "        return None\n",
    "\n",
    "    def write_calibration_cache(self, cache, *args, **kwargs):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7822ffcd-f5e4-4ec7-b124-aaa4f3c92cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_int8=True\n",
    "if use_int8:\n",
    "    data = torch.zeros(batch_size, 3, DIM, DIM)\n",
    "    config.set_flag(trt.BuilderFlag.INT8)\n",
    "    \n",
    "    val_loader = tud.DataLoader(val, batch_size=trt_batch_size, shuffle=True)\n",
    "    config.int8_calibrator = DatasetCalibrator(data, val_loader.dataset)\n",
    "else:\n",
    "    config.set_flag(trt.BuilderFlag.FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576b728-9069-4cb1-b297-f87f49210e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "engine = builder.build_serialized_network(network, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997a850-8195-4651-bb0c-248a5a40569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sparse_resnet.engine\", 'wb') as f:\n",
    "    f.write(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8619c-f956-41f2-a474-e6b281ef592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/NVIDIA/TensorRT/tree/main/samples/python/yolov3_onnx\n",
    "import tensorrt as trt\n",
    "\n",
    "logger = trt.Logger()\n",
    "runtime = trt.Runtime(logger)\n",
    "with open(\"sparse_resnet.engine\", 'rb') as f:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4db54d-ad65-448d-a210-e1015762b28a",
   "metadata": {},
   "source": [
    "Profile the engine:\n",
    "`trtexec --loadEngine=sparse_resnet.engine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1166522-f118-4f75-af08-62ea8e1b6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use \"get_tensor_name\" instead\n",
    "for i in range(engine.num_io_tensors):\n",
    "    \n",
    "input_binding_idx = engine.get_tensor_name(0)\n",
    "output_binding_idx = engine.get_tensor_name('output')\n",
    "\n",
    "input_shape = (1, 3, DIM, DIM)\n",
    "output_shape = (1, 3, DIM, DIM)\n",
    "\n",
    "# Use \"set_input_shape\" instead\n",
    "context.set_binding_shape(\n",
    "    input_binding_idx,\n",
    "    input_shape\n",
    ")\n",
    "\n",
    "input_buffer = torch.zeros(input_shape, dtype=torch.float32, device=torch.device('cuda'))\n",
    "output_buffer = torch.zeros(output_shape, dtype=torch.float32, device=torch.device('cuda'))\n",
    "\n",
    "bindings = [None, None]\n",
    "bindings[input_binding_idx] = input_buffer.data_ptr()\n",
    "bindings[output_binding_idx] = output_buffer.data_ptr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
